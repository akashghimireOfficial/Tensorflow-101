{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Embedding,GlobalAvgPool1D,TextVectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os \n",
    "import shutil\n",
    "import string\n",
    "import re\n",
    "from os.path import join\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb.vocab', 'imdbEr.txt', 'README', 'test', 'train']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n",
    "                                  untar=True, cache_dir='.',\n",
    "                                  cache_subdir='')\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=join(dataset_dir,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labeledBow.feat',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'unsup',\n",
       " 'unsupBow.feat',\n",
       " 'urls_neg.txt',\n",
       " 'urls_pos.txt',\n",
       " 'urls_unsup.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'neg' folders contains Negative review, \n",
    "\n",
    "'pos' folders contains Positive review, \n",
    "\n",
    "For this turtorial we will not require 'unsup' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir=join(train_dir,'unsup')\n",
    "\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labeledBow.feat',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'unsupBow.feat',\n",
       " 'urls_neg.txt',\n",
       " 'urls_pos.txt',\n",
       " 'urls_unsup.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Text:::\n",
      " Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n"
     ]
    }
   ],
   "source": [
    "## Let us see how is the positve text \n",
    "\n",
    "pos_text_dires=glob(join(train_dir,'pos')+'/*txt')\n",
    "\n",
    "with open(pos_text_dires[0],mode='rb') as file:\n",
    "    pos_text=file.read().decode('UTF-8')\n",
    "    \n",
    "print('Positive Text:::\\n',pos_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Text:::\n",
      " Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n"
     ]
    }
   ],
   "source": [
    "## Let us see how is the positve text \n",
    "\n",
    "neg_text_dires=glob(join(train_dir,'neg')+'/*txt')\n",
    "\n",
    "with open(neg_text_dires[0],mode='rb') as file:\n",
    "    neg_text=file.read().decode('UTF-8')\n",
    "    \n",
    "print('Negative Text:::\\n',neg_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "seed = 123\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train', batch_size=batch_size, validation_split=0.2,\n",
    "    subset='training', seed=seed)\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train', batch_size=batch_size, validation_split=0.2,\n",
    "    subset='validation', seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _walk at 0x0000020005C8F4A0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.walk('aclImdb/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :  tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(b\"In a series chock-full of brilliant episodes, this one stands out as one of my very favorites. It's not the most profound episode, there's no great meaning or message. But it's a lot of fun, and there are some fine performances.<br /><br />But what makes it really stand out for me is that it is, to my knowledge, the *only* Twilight Zone episode with a *double* snapper ending. The Zone is rightly famous for providing a big surprise at the end of a story. But this time, you get a surprise, and think that's that, but it turns out there's *another* surprise waiting. I just like that so much, that this is probably one of my two favorite episodes (the other being a deeper, more message-oriented one).\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for text_data,label in train_ds.take(1):\n",
    "    print('Label : ', label[0])\n",
    "    print(text_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to simplify our task, we need to do some preprocessing of the text: \n",
    "- Lowecase Every Character \n",
    "- remove some special character like '<br>' and replace it with ' '(Removing HTML syntax) \n",
    "- And remove all the specific punctuations like *@, #, $,%,&*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "## let us see the special Puntuations \n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World This is an example\n"
     ]
    }
   ],
   "source": [
    "stripped_html = \"Hello, [World]! This is an example.\"\n",
    "pattern = '[%s]' % re.escape(string.punctuation)\n",
    "result = re.sub(pattern, '', stripped_html)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining using tensoroperation\n",
    "\n",
    "def custom_standerization(input_data):\n",
    "    lowercase=tf.strings.lower(input_data)\n",
    "    stripped_html=tf.strings.regex_replace(lowercase,'<br>',' ')\n",
    "    stripped_punc=tf.strings.regex_replace(stripped_html,'[%s]' % re.escape(string.punctuation),'')\n",
    "    return stripped_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'oh my god please for the love of all that is holy do not watch this movie it it 82 minutes of my life i will never get back sure i could have stopped watching half way through but i thought it might get better it didnt anyone who actually enjoyed this movie is one seriously sick and twisted individual no wonder us australiansnew zealanders have a terrible reputation when it comes to making movies everything about this movie is horrible from the acting to the editing i dont even normally write reviews on here but in this case ill make an exception i only wish someone had of warned me before i hired this catastrophe'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_standerization(text_data[0]) ## Applying this to above text_data from train_ds.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextVectorizing the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining the vocab_size, and seq_length(numbers of words in a sequence)\n",
    "\n",
    "vocab_size=10000\n",
    "sequence_length=100\n",
    "\n",
    "## Defining text_vectorization \n",
    "\n",
    "vectorize_layer=TextVectorization(standardize=custom_standerization,\n",
    "                                 max_tokens=vocab_size,\n",
    "                                 output_mode='int',\n",
    "                                 output_sequence_length=sequence_length)\n",
    "\n",
    "## We have to apply the vectorization to only text of dataset\n",
    "\n",
    "text_ds=train_ds.map(lambda x,y:x) ## We only adapt to text_ds\n",
    "\n",
    "##In the training, vectorize_layer only affect text data of train_ds not text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]']\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorize_layer.get_vocabulary()\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"Wow. Some movies just leave me speechless. This was undeniably one of those movies. When I left the theatre, not a single word came to my mouth. All I had was an incredible urge to slam my head against the theatre wall to help me forget about the last hour and a half. Unfortunately, it didn't work. Honestly, this movie has nothing to recommend. The humor was at the first grade level, at best, the acting was overly silly, and the plot was astronomically far-fetched. I hearby pledge never to see an other movie starring Chris Kattan or any other cast-member of SNL.\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "## before adapt\n",
    "\n",
    "for vec_text in text_ds.take(1): ## Why no preprocessing \n",
    "    print(vec_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'I believe this is the most powerful film HBO Pictures has made to date. This film should have been released in theaters for the public to view on the big screen. It is available on video so make sure you look for it and check it out. Chris Gerolmo did a great job with the direction and the screenplay. The performances from Stephen Rea, Donald Sutherland and Jeffery DeMunn are flawless. A masterpiece of the genre.', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "## After Adapting\n",
    "for vec_text in text_ds.take(1): \n",
    "    print(vec_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a classification model and Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=16\n",
    "\n",
    "model = Sequential([\n",
    "  vectorize_layer,\n",
    "  Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n",
    "  GlobalAvgPool1D(),\n",
    "  Dense(16, activation='relu'),\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "20/20 [==============================] - 13s 415ms/step - loss: 0.6922 - accuracy: 0.5028 - val_loss: 0.6907 - val_accuracy: 0.4886\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 6s 221ms/step - loss: 0.6882 - accuracy: 0.5028 - val_loss: 0.6854 - val_accuracy: 0.4886\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 6s 219ms/step - loss: 0.6812 - accuracy: 0.5028 - val_loss: 0.6770 - val_accuracy: 0.4886\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 6s 220ms/step - loss: 0.6699 - accuracy: 0.5028 - val_loss: 0.6638 - val_accuracy: 0.4886\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 6s 218ms/step - loss: 0.6535 - accuracy: 0.5028 - val_loss: 0.6462 - val_accuracy: 0.4886\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 6s 222ms/step - loss: 0.6319 - accuracy: 0.5032 - val_loss: 0.6239 - val_accuracy: 0.4926\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 6s 217ms/step - loss: 0.6056 - accuracy: 0.5397 - val_loss: 0.5985 - val_accuracy: 0.5698\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 6s 220ms/step - loss: 0.5754 - accuracy: 0.6281 - val_loss: 0.5705 - val_accuracy: 0.6298\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 5s 216ms/step - loss: 0.5430 - accuracy: 0.6896 - val_loss: 0.5428 - val_accuracy: 0.6690\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 5s 215ms/step - loss: 0.5105 - accuracy: 0.7353 - val_loss: 0.5158 - val_accuracy: 0.7168\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 6s 220ms/step - loss: 0.4798 - accuracy: 0.7642 - val_loss: 0.4921 - val_accuracy: 0.7364\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 6s 216ms/step - loss: 0.4515 - accuracy: 0.7875 - val_loss: 0.4718 - val_accuracy: 0.7512\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 6s 220ms/step - loss: 0.4264 - accuracy: 0.8065 - val_loss: 0.4550 - val_accuracy: 0.7578\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 6s 221ms/step - loss: 0.4041 - accuracy: 0.8188 - val_loss: 0.4398 - val_accuracy: 0.7712\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 6s 220ms/step - loss: 0.3842 - accuracy: 0.8288 - val_loss: 0.4285 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe7da072e0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "example=tf.constant(['This movie was so good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_review(model,text):\n",
    "    text=text[tf.newaxis]\n",
    "    pred_logit=model.predict(text)\n",
    "    prob=tf.sigmoid(pred_logit)\n",
    "    \n",
    "    if prob >=0.5:\n",
    "        print(\"Positive Review\")\n",
    "    else:\n",
    "        print(\"Negative Review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "Positive Review\n"
     ]
    }
   ],
   "source": [
    "movie_review(model,tf.constant(['The movie was boring']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9441a693079ae470\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9441a693079ae470\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'the',\n",
       " 'and',\n",
       " 'a',\n",
       " 'of',\n",
       " 'to',\n",
       " 'is',\n",
       " 'in',\n",
       " 'it',\n",
       " 'i',\n",
       " 'this',\n",
       " 'that',\n",
       " 'br',\n",
       " 'was',\n",
       " 'as',\n",
       " 'with',\n",
       " 'for',\n",
       " 'movie',\n",
       " 'but',\n",
       " 'film',\n",
       " 'on',\n",
       " 'not',\n",
       " 'you',\n",
       " 'are',\n",
       " 'his',\n",
       " 'have',\n",
       " 'be',\n",
       " 'he',\n",
       " 'one',\n",
       " 'its',\n",
       " 'at',\n",
       " 'all',\n",
       " 'by',\n",
       " 'an',\n",
       " 'they',\n",
       " 'who',\n",
       " 'from',\n",
       " 'so',\n",
       " 'like',\n",
       " 'her',\n",
       " 'just',\n",
       " 'or',\n",
       " 'about',\n",
       " 'has',\n",
       " 'if',\n",
       " 'out',\n",
       " 'some',\n",
       " 'there',\n",
       " 'what',\n",
       " 'good',\n",
       " 'when',\n",
       " 'more',\n",
       " 'very',\n",
       " 'even',\n",
       " 'she',\n",
       " 'my',\n",
       " 'up',\n",
       " 'no',\n",
       " 'would',\n",
       " 'only',\n",
       " 'which',\n",
       " 'time',\n",
       " 'really',\n",
       " 'story',\n",
       " 'their',\n",
       " 'see',\n",
       " 'had',\n",
       " 'were',\n",
       " 'can',\n",
       " 'me',\n",
       " 'we',\n",
       " 'than',\n",
       " 'much',\n",
       " 'well',\n",
       " 'been',\n",
       " 'will',\n",
       " 'get',\n",
       " 'also',\n",
       " 'people',\n",
       " 'into',\n",
       " 'do',\n",
       " 'other',\n",
       " 'first',\n",
       " 'bad',\n",
       " 'great',\n",
       " 'because',\n",
       " 'how',\n",
       " 'most',\n",
       " 'him',\n",
       " 'dont',\n",
       " 'made',\n",
       " 'then',\n",
       " 'movies',\n",
       " 'make',\n",
       " 'could',\n",
       " 'way',\n",
       " 'films',\n",
       " 'any',\n",
       " 'them',\n",
       " 'after',\n",
       " 'too',\n",
       " 'characters',\n",
       " 'think',\n",
       " 'watch',\n",
       " 'being',\n",
       " 'two',\n",
       " 'many',\n",
       " 'seen',\n",
       " 'character',\n",
       " 'never',\n",
       " 'little',\n",
       " 'where',\n",
       " 'plot',\n",
       " 'acting',\n",
       " 'best',\n",
       " 'did',\n",
       " 'love',\n",
       " 'know',\n",
       " 'life',\n",
       " 'does',\n",
       " 'show',\n",
       " 'ever',\n",
       " 'your',\n",
       " 'over',\n",
       " 'better',\n",
       " 'still',\n",
       " 'off',\n",
       " 'end',\n",
       " 'these',\n",
       " 'say',\n",
       " 'man',\n",
       " 'why',\n",
       " 'scene',\n",
       " 'here',\n",
       " 'while',\n",
       " 'scenes',\n",
       " 'such',\n",
       " 'go',\n",
       " 'should',\n",
       " 'something',\n",
       " 'through',\n",
       " 'im',\n",
       " 'back',\n",
       " 'those',\n",
       " 'real',\n",
       " 'doesnt',\n",
       " 'watching',\n",
       " 'years',\n",
       " 'though',\n",
       " 'now',\n",
       " 'thing',\n",
       " 'another',\n",
       " 'didnt',\n",
       " 'actors',\n",
       " 'actually',\n",
       " 'before',\n",
       " 'new',\n",
       " 'nothing',\n",
       " 'makes',\n",
       " 'find',\n",
       " 'funny',\n",
       " 'look',\n",
       " 'work',\n",
       " 'old',\n",
       " 'going',\n",
       " 'same',\n",
       " 'few',\n",
       " 'part',\n",
       " 'every',\n",
       " 'lot',\n",
       " 'us',\n",
       " 'director',\n",
       " 'again',\n",
       " 'want',\n",
       " 'cast',\n",
       " 'thats',\n",
       " 'cant',\n",
       " 'quite',\n",
       " 'seems',\n",
       " 'young',\n",
       " 'pretty',\n",
       " 'things',\n",
       " 'around',\n",
       " 'got',\n",
       " 'however',\n",
       " 'fact',\n",
       " 'world',\n",
       " 'down',\n",
       " 'take',\n",
       " 'enough',\n",
       " 'both',\n",
       " 'give',\n",
       " 'between',\n",
       " 'own',\n",
       " 'may',\n",
       " 'thought',\n",
       " 'original',\n",
       " 'horror',\n",
       " 'ive',\n",
       " 'big',\n",
       " 'always',\n",
       " 'series',\n",
       " 'without',\n",
       " 'gets',\n",
       " 'isnt',\n",
       " 'almost',\n",
       " 'right',\n",
       " 'long',\n",
       " 'saw',\n",
       " 'point',\n",
       " 'theres',\n",
       " 'role',\n",
       " 'action',\n",
       " 'come',\n",
       " 'interesting',\n",
       " 'times',\n",
       " 'whole',\n",
       " 'least',\n",
       " 'must',\n",
       " 'bit',\n",
       " 'done',\n",
       " 'comedy',\n",
       " 'might',\n",
       " 'guy',\n",
       " 'family',\n",
       " 'hes',\n",
       " 'music',\n",
       " 'last',\n",
       " 'anything',\n",
       " 'script',\n",
       " 'minutes',\n",
       " 'far',\n",
       " 'since',\n",
       " 'feel',\n",
       " 'probably',\n",
       " 'performance',\n",
       " 'am',\n",
       " 'sure',\n",
       " 'kind',\n",
       " 'yet',\n",
       " 'rather',\n",
       " 'away',\n",
       " 'worst',\n",
       " 'tv',\n",
       " 'woman',\n",
       " 'played',\n",
       " 'girl',\n",
       " 'making',\n",
       " 'fun',\n",
       " 'anyone',\n",
       " 'found',\n",
       " 'each',\n",
       " 'having',\n",
       " 'comes',\n",
       " 'our',\n",
       " 'believe',\n",
       " 'course',\n",
       " 'although',\n",
       " 'trying',\n",
       " 'goes',\n",
       " 'shows',\n",
       " 'looks',\n",
       " 'especially',\n",
       " 'day',\n",
       " 'put',\n",
       " 'hard',\n",
       " 'wasnt',\n",
       " 'place',\n",
       " 'different',\n",
       " 'maybe',\n",
       " 'once',\n",
       " 'sense',\n",
       " 'worth',\n",
       " 'set',\n",
       " 'main',\n",
       " 'true',\n",
       " 'reason',\n",
       " 'looking',\n",
       " 'watched',\n",
       " 'money',\n",
       " 'someone',\n",
       " 'ending',\n",
       " 'job',\n",
       " 'everything',\n",
       " 'said',\n",
       " 'book',\n",
       " 'takes',\n",
       " 'screen',\n",
       " 'dvd',\n",
       " 'plays',\n",
       " 'during',\n",
       " 'actor',\n",
       " 'three',\n",
       " 'later',\n",
       " 'play',\n",
       " 'seem',\n",
       " '2',\n",
       " 'instead',\n",
       " 'effects',\n",
       " 'together',\n",
       " 'everyone',\n",
       " 'version',\n",
       " 'audience',\n",
       " 'himself',\n",
       " 'seeing',\n",
       " '10',\n",
       " 'left',\n",
       " 'night',\n",
       " 'special',\n",
       " 'john',\n",
       " 'beautiful',\n",
       " 'american',\n",
       " 'excellent',\n",
       " 'house',\n",
       " 'nice',\n",
       " 'idea',\n",
       " 'simply',\n",
       " 'youre',\n",
       " 'shot',\n",
       " 'high',\n",
       " 'wife',\n",
       " 'read',\n",
       " 'kids',\n",
       " 'black',\n",
       " 'less',\n",
       " 'fan',\n",
       " 'completely',\n",
       " 'help',\n",
       " 'second',\n",
       " 'war',\n",
       " 'else',\n",
       " 'star',\n",
       " 'year',\n",
       " 'used',\n",
       " 'rest',\n",
       " 'try',\n",
       " 'poor',\n",
       " 'use',\n",
       " 'friends',\n",
       " 'need',\n",
       " 'given',\n",
       " 'men',\n",
       " 'classic',\n",
       " 'death',\n",
       " 'home',\n",
       " 'performances',\n",
       " 'mind',\n",
       " 'until',\n",
       " 'hollywood',\n",
       " 'short',\n",
       " 'enjoy',\n",
       " 'either',\n",
       " 'half',\n",
       " 'father',\n",
       " 'along',\n",
       " 'truly',\n",
       " 'wrong',\n",
       " 'women',\n",
       " 'tell',\n",
       " 'boring',\n",
       " 'next',\n",
       " 'dead',\n",
       " 'line',\n",
       " 'came',\n",
       " 'remember',\n",
       " 'couple',\n",
       " 'start',\n",
       " 'wonderful',\n",
       " 'production',\n",
       " 'recommend',\n",
       " 'getting',\n",
       " 'mean',\n",
       " 'full',\n",
       " 'let',\n",
       " 'understand',\n",
       " 'perhaps',\n",
       " 'playing',\n",
       " 'terrible',\n",
       " 'others',\n",
       " 'awful',\n",
       " 'stupid',\n",
       " 'gives',\n",
       " 'face',\n",
       " 'definitely',\n",
       " 'camera',\n",
       " 'doing',\n",
       " 'often',\n",
       " 'keep',\n",
       " 'small',\n",
       " 'sex',\n",
       " 'moments',\n",
       " 'early',\n",
       " 'become',\n",
       " 'video',\n",
       " 'name',\n",
       " 'episode',\n",
       " 'school',\n",
       " 'dialogue',\n",
       " 'supposed',\n",
       " 'perfect',\n",
       " 'itself',\n",
       " 'person',\n",
       " 'human',\n",
       " 'liked',\n",
       " 'lines',\n",
       " 'top',\n",
       " 'sort',\n",
       " 'lost',\n",
       " 'finally',\n",
       " 'felt',\n",
       " 'yes',\n",
       " 'entire',\n",
       " 'couldnt',\n",
       " 'went',\n",
       " 'stars',\n",
       " 'title',\n",
       " 'evil',\n",
       " 'piece',\n",
       " 'case',\n",
       " 'problem',\n",
       " 'absolutely',\n",
       " 'hope',\n",
       " 'against',\n",
       " 'waste',\n",
       " 'live',\n",
       " 'shes',\n",
       " 'written',\n",
       " 'budget',\n",
       " 'certainly',\n",
       " 'loved',\n",
       " 'fans',\n",
       " 'white',\n",
       " 'style',\n",
       " 'head',\n",
       " 'several',\n",
       " 'picture',\n",
       " 'cinema',\n",
       " 'based',\n",
       " 'overall',\n",
       " 'worse',\n",
       " 'becomes',\n",
       " 'id',\n",
       " 'oh',\n",
       " 'killer',\n",
       " 'example',\n",
       " 'entertaining',\n",
       " 'direction',\n",
       " 'seemed',\n",
       " 'boy',\n",
       " 'beginning',\n",
       " 'mr',\n",
       " 'guys',\n",
       " 'mother',\n",
       " '\\x96',\n",
       " 'care',\n",
       " 'dark',\n",
       " 'unfortunately',\n",
       " 'turn',\n",
       " '3',\n",
       " 'despite',\n",
       " 'throughout',\n",
       " 'already',\n",
       " 'final',\n",
       " 'wanted',\n",
       " 'drama',\n",
       " 'lives',\n",
       " 'amazing',\n",
       " 'laugh',\n",
       " 'low',\n",
       " 'friend',\n",
       " 'tries',\n",
       " 'children',\n",
       " 'wont',\n",
       " 'fine',\n",
       " 'totally',\n",
       " 'sound',\n",
       " 'youll',\n",
       " 'under',\n",
       " 'works',\n",
       " 'lead',\n",
       " 'history',\n",
       " 'guess',\n",
       " '1',\n",
       " 'girls',\n",
       " 'writing',\n",
       " 'wants',\n",
       " 'theyre',\n",
       " 'called',\n",
       " 'humor',\n",
       " 'able',\n",
       " 'turns',\n",
       " 'act',\n",
       " 'favorite',\n",
       " 'past',\n",
       " 'behind',\n",
       " 'starts',\n",
       " 'michael',\n",
       " 'enjoyed',\n",
       " 'gave',\n",
       " 'quality',\n",
       " 'days',\n",
       " 'sometimes',\n",
       " 'kill',\n",
       " 'child',\n",
       " 'game',\n",
       " 'viewer',\n",
       " 'soon',\n",
       " 'side',\n",
       " 'parts',\n",
       " 'town',\n",
       " 'flick',\n",
       " 'son',\n",
       " 'themselves',\n",
       " 'car',\n",
       " 'thinking',\n",
       " 'ones',\n",
       " 'genre',\n",
       " 'eyes',\n",
       " 'heart',\n",
       " 'directed',\n",
       " 'expect',\n",
       " 'obviously',\n",
       " 'art',\n",
       " 'feeling',\n",
       " 'decent',\n",
       " 'brilliant',\n",
       " 'ill',\n",
       " 'says',\n",
       " 'horrible',\n",
       " 'stories',\n",
       " 'actress',\n",
       " 'late',\n",
       " 'fight',\n",
       " 'close',\n",
       " 'highly',\n",
       " 'killed',\n",
       " 'stuff',\n",
       " 'happens',\n",
       " 'cannot',\n",
       " 'heard',\n",
       " 'run',\n",
       " 'moment',\n",
       " 'took',\n",
       " 'blood',\n",
       " 'particularly',\n",
       " 'myself',\n",
       " 'leave',\n",
       " 'wouldnt',\n",
       " 'city',\n",
       " 'hour',\n",
       " 'except',\n",
       " 'extremely',\n",
       " 'wonder',\n",
       " 'matter',\n",
       " 'kid',\n",
       " 'hell',\n",
       " 'hand',\n",
       " 'etc',\n",
       " 'attempt',\n",
       " 'happened',\n",
       " 'roles',\n",
       " 'strong',\n",
       " 'police',\n",
       " 'involved',\n",
       " 'anyway',\n",
       " 'obvious',\n",
       " 'lack',\n",
       " 'complete',\n",
       " 'told',\n",
       " 'chance',\n",
       " 'james',\n",
       " 'group',\n",
       " 'coming',\n",
       " 'including',\n",
       " 'voice',\n",
       " 'itbr',\n",
       " 'violence',\n",
       " 'type',\n",
       " 'daughter',\n",
       " 'looked',\n",
       " 'living',\n",
       " 'please',\n",
       " 'happen',\n",
       " 'murder',\n",
       " 'save',\n",
       " 'alone',\n",
       " 'number',\n",
       " 'shown',\n",
       " 'usually',\n",
       " 'ok',\n",
       " 'lets',\n",
       " 'score',\n",
       " 'god',\n",
       " 'age',\n",
       " 'stop',\n",
       " 'taken',\n",
       " 'none',\n",
       " 'simple',\n",
       " 'interest',\n",
       " 'ago',\n",
       " 'yourself',\n",
       " 'slow',\n",
       " 'experience',\n",
       " 'exactly',\n",
       " 'ends',\n",
       " 'david',\n",
       " 'annoying',\n",
       " 'usual',\n",
       " 'mostly',\n",
       " 'cinematography',\n",
       " 'opening',\n",
       " 'career',\n",
       " 'whose',\n",
       " 'across',\n",
       " 'known',\n",
       " 'finds',\n",
       " 'song',\n",
       " 'started',\n",
       " 'hilarious',\n",
       " 'scary',\n",
       " 'sad',\n",
       " 'huge',\n",
       " 'hit',\n",
       " 'episodes',\n",
       " 'released',\n",
       " 'relationship',\n",
       " 'english',\n",
       " 'musical',\n",
       " 'hours',\n",
       " 'cut',\n",
       " 'serious',\n",
       " 'robert',\n",
       " 'possible',\n",
       " 'brother',\n",
       " 'wish',\n",
       " 'somewhat',\n",
       " 'seriously',\n",
       " 'major',\n",
       " 'shots',\n",
       " 'running',\n",
       " 'jokes',\n",
       " 'order',\n",
       " 'cool',\n",
       " 'change',\n",
       " 'taking',\n",
       " 'female',\n",
       " 'reality',\n",
       " 'hero',\n",
       " 'body',\n",
       " '4',\n",
       " 'gore',\n",
       " 'saying',\n",
       " 'opinion',\n",
       " 'crap',\n",
       " 'events',\n",
       " 'view',\n",
       " 'ridiculous',\n",
       " 'knew',\n",
       " 'call',\n",
       " 'directors',\n",
       " 'strange',\n",
       " 'today',\n",
       " 'knows',\n",
       " 'talking',\n",
       " 'power',\n",
       " '5',\n",
       " 'turned',\n",
       " 'supporting',\n",
       " 'king',\n",
       " 'happy',\n",
       " 'basically',\n",
       " 'level',\n",
       " 'arent',\n",
       " 'apparently',\n",
       " 'due',\n",
       " 'room',\n",
       " 'clearly',\n",
       " 'attention',\n",
       " 'tells',\n",
       " 'local',\n",
       " 'documentary',\n",
       " 'novel',\n",
       " 'sequence',\n",
       " 'easily',\n",
       " 'rating',\n",
       " 'moviebr',\n",
       " 'songs',\n",
       " 'modern',\n",
       " 'husband',\n",
       " 'british',\n",
       " 'appears',\n",
       " 'falls',\n",
       " 'words',\n",
       " 'talent',\n",
       " 'whether',\n",
       " 'sets',\n",
       " 'bring',\n",
       " 'future',\n",
       " 'important',\n",
       " 'country',\n",
       " 'beyond',\n",
       " 'whats',\n",
       " 'problems',\n",
       " 'word',\n",
       " 'four',\n",
       " 'cheap',\n",
       " 'viewers',\n",
       " 'single',\n",
       " 'predictable',\n",
       " 'needs',\n",
       " 'similar',\n",
       " 'romantic',\n",
       " 'giving',\n",
       " 'comic',\n",
       " 'miss',\n",
       " 'light',\n",
       " 'television',\n",
       " 'jack',\n",
       " 'review',\n",
       " 'add',\n",
       " 'silly',\n",
       " 'havent',\n",
       " 'five',\n",
       " 'actual',\n",
       " 'disappointed',\n",
       " 'earth',\n",
       " 'within',\n",
       " 'talk',\n",
       " 'mention',\n",
       " 'animation',\n",
       " 'upon',\n",
       " 'lots',\n",
       " 'george',\n",
       " 'entertainment',\n",
       " 'feels',\n",
       " 'enjoyable',\n",
       " 'begins',\n",
       " 'nearly',\n",
       " 'lady',\n",
       " 'storyline',\n",
       " 'bunch',\n",
       " 'using',\n",
       " 'paul',\n",
       " 'herself',\n",
       " 'filmbr',\n",
       " 'sequel',\n",
       " 'named',\n",
       " 'moving',\n",
       " 'sorry',\n",
       " 'ways',\n",
       " 'surprised',\n",
       " 'rock',\n",
       " 'richard',\n",
       " 'message',\n",
       " 'above',\n",
       " 'comments',\n",
       " 'points',\n",
       " 'theme',\n",
       " 'dull',\n",
       " 'ten',\n",
       " 'team',\n",
       " 'stay',\n",
       " 'showing',\n",
       " 'dialog',\n",
       " 'thriller',\n",
       " 'middle',\n",
       " 'somehow',\n",
       " 'typical',\n",
       " 'avoid',\n",
       " 'theater',\n",
       " 'fall',\n",
       " 'fantastic',\n",
       " 'doubt',\n",
       " 'mystery',\n",
       " 'parents',\n",
       " 'easy',\n",
       " 'york',\n",
       " 'release',\n",
       " 'writer',\n",
       " 'near',\n",
       " 'leads',\n",
       " 'kept',\n",
       " 'certain',\n",
       " 'among',\n",
       " 'hate',\n",
       " 'tried',\n",
       " 'elements',\n",
       " 'weak',\n",
       " 'tale',\n",
       " 'famous',\n",
       " 'effort',\n",
       " 'sister',\n",
       " 'means',\n",
       " 'working',\n",
       " 'general',\n",
       " 'feature',\n",
       " 'learn',\n",
       " 'viewing',\n",
       " 'soundtrack',\n",
       " 'particular',\n",
       " 'straight',\n",
       " 'filmed',\n",
       " 'figure',\n",
       " 'clear',\n",
       " 'class',\n",
       " 'greatest',\n",
       " 'gone',\n",
       " 'brought',\n",
       " 'eventually',\n",
       " 'buy',\n",
       " 'realistic',\n",
       " 'fast',\n",
       " 'editing',\n",
       " 'form',\n",
       " 'eye',\n",
       " 'hear',\n",
       " 'dance',\n",
       " 'season',\n",
       " 'de',\n",
       " 'sequences',\n",
       " 'red',\n",
       " 'zombie',\n",
       " 'french',\n",
       " 'check',\n",
       " 'youve',\n",
       " 'imagine',\n",
       " 'oscar',\n",
       " 'follow',\n",
       " 'material',\n",
       " 'move',\n",
       " 'reviews',\n",
       " 'decided',\n",
       " 'whos',\n",
       " 'space',\n",
       " 'atmosphere',\n",
       " 'tom',\n",
       " 'forget',\n",
       " 'deal',\n",
       " 'wait',\n",
       " 'lame',\n",
       " 'sit',\n",
       " 'whatever',\n",
       " 'third',\n",
       " 'became',\n",
       " 'stand',\n",
       " 'peter',\n",
       " 'expected',\n",
       " 'poorly',\n",
       " 'period',\n",
       " 'die',\n",
       " 'possibly',\n",
       " 'meets',\n",
       " 'difficult',\n",
       " 'okay',\n",
       " 'truth',\n",
       " 'lee',\n",
       " 'indeed',\n",
       " 'killing',\n",
       " 'note',\n",
       " 'nature',\n",
       " 'surprise',\n",
       " 'leaves',\n",
       " 'nor',\n",
       " 'writers',\n",
       " 'subject',\n",
       " 'japanese',\n",
       " 'filmmakers',\n",
       " 'premise',\n",
       " 'screenplay',\n",
       " 'rent',\n",
       " 'believable',\n",
       " 'stage',\n",
       " 'romance',\n",
       " 'reading',\n",
       " 'needed',\n",
       " 'average',\n",
       " 'question',\n",
       " 'write',\n",
       " 'suspense',\n",
       " 'sexual',\n",
       " 'memorable',\n",
       " 'superb',\n",
       " 'crime',\n",
       " 'interested',\n",
       " '80s',\n",
       " 'keeps',\n",
       " 'dr',\n",
       " 'dramatic',\n",
       " 'street',\n",
       " 'meet',\n",
       " 'older',\n",
       " 'boys',\n",
       " 'unless',\n",
       " 'forced',\n",
       " 'emotional',\n",
       " 'begin',\n",
       " 'disney',\n",
       " 'realize',\n",
       " 'features',\n",
       " 'minute',\n",
       " 'footage',\n",
       " 'whom',\n",
       " 'total',\n",
       " 'previous',\n",
       " 'otherwise',\n",
       " 'joe',\n",
       " 'result',\n",
       " 'badly',\n",
       " 'earlier',\n",
       " 'crazy',\n",
       " 'baby',\n",
       " 'situation',\n",
       " 'society',\n",
       " 'towards',\n",
       " 'personal',\n",
       " 'comment',\n",
       " 'incredibly',\n",
       " 'brings',\n",
       " 'male',\n",
       " 'hot',\n",
       " 'directing',\n",
       " 'ask',\n",
       " 'weird',\n",
       " 'shame',\n",
       " 'cheesy',\n",
       " 'sounds',\n",
       " 'dog',\n",
       " 'beauty',\n",
       " 'appear',\n",
       " 'twist',\n",
       " 'hands',\n",
       " 'development',\n",
       " 'credits',\n",
       " 'return',\n",
       " 'remake',\n",
       " 'leading',\n",
       " 'background',\n",
       " 'b',\n",
       " 'plenty',\n",
       " 'open',\n",
       " 'imdb',\n",
       " 'fairly',\n",
       " 'effect',\n",
       " 'creepy',\n",
       " 'apart',\n",
       " 'secret',\n",
       " 'portrayed',\n",
       " 'unique',\n",
       " 'scifi',\n",
       " 'plus',\n",
       " 'admit',\n",
       " 'meant',\n",
       " 'laughs',\n",
       " 'ideas',\n",
       " 'hardly',\n",
       " 'america',\n",
       " '70s',\n",
       " '20',\n",
       " 'perfectly',\n",
       " 'deep',\n",
       " 'worked',\n",
       " 'quickly',\n",
       " 'mark',\n",
       " 'casting',\n",
       " 'gay',\n",
       " 'forward',\n",
       " 'mess',\n",
       " 'powerful',\n",
       " 'free',\n",
       " 'christmas',\n",
       " 'attempts',\n",
       " 'unlike',\n",
       " 'missing',\n",
       " 'create',\n",
       " 'present',\n",
       " 'business',\n",
       " 'expecting',\n",
       " 'various',\n",
       " 'setting',\n",
       " 'rich',\n",
       " 'nudity',\n",
       " 'inside',\n",
       " 'la',\n",
       " 'fantasy',\n",
       " 'battle',\n",
       " 'fire',\n",
       " 'dumb',\n",
       " 'dream',\n",
       " 'potential',\n",
       " 'fails',\n",
       " 'brothers',\n",
       " 'break',\n",
       " 'recently',\n",
       " 'western',\n",
       " 'political',\n",
       " 'pay',\n",
       " 'outside',\n",
       " 'fighting',\n",
       " 'manages',\n",
       " ...]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
