{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nSteps involved: Creating a tf dataset using sourse daatset. Prprocessing them , ........\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## One of the easiest way to create tf.data is using tf.\n",
    "\"\"\"\"\n",
    "Steps involved: Creating a tf dataset using sourse daatset. Prprocessing them , ........\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOne of the easiest way of creating tf.data.Dataset is using either tf.data.Dataset.from_tensors and tf.data.Data.from_tensor_slices.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "One of the easiest way of creating tf.data.Dataset is using either tf.data.Dataset.from_tensors and tf.data.Data.from_tensor_slices.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tf dataset from tf constant:  <TensorDataset element_spec=TensorSpec(shape=(3,), dtype=tf.float32, name=None)>\n",
      "Creating tf dataset from tf Variable  <TensorDataset element_spec=TensorSpec(shape=(3,), dtype=tf.float32, name=None)>\n",
      "\n",
      "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf_tensor1=tf.constant([1,2,3],dtype=tf.float32)\n",
    "tf_tensor2=tf.Variable([1,2,3],dtype=tf.float32)\n",
    "\n",
    "# We use tf.data.Dataset.from_tensors when are are dealing with single element. \n",
    "\n",
    "dataset1=tf.data.Dataset.from_tensors(tf_tensor1)\n",
    "dataset2=tf.data.Dataset.from_tensors(tf_tensor2)\n",
    "\n",
    "print('Creating tf dataset from tf constant: ',dataset1)\n",
    "print('Creating tf dataset from tf Variable ',dataset2)\n",
    "\n",
    "# tf.data.Dataset Object is ia iterator.(Doesn't directly load to memory.). Each item in those iterable are called \"element\"\n",
    "print()\n",
    "for element in dataset1:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset from tensor having more than a single element : \n",
      " <TensorSliceDataset element_spec=TensorSpec(shape=(5,), dtype=tf.float32, name=None)>\n",
      "tf.Tensor([ 0.12589556 -0.29566288 -1.4196749   0.19035274  1.0202717 ], shape=(5,), dtype=float32)\n",
      "tf.Tensor([-0.8924672  -0.6257301  -0.62866145 -0.3998429  -1.3638616 ], shape=(5,), dtype=float32)\n",
      "tf.Tensor([ 0.4574584  -1.2954105   0.5549091   0.16850777 -0.02755504], shape=(5,), dtype=float32)\n",
      "tf.Tensor([2.4304144 1.1543106 2.1211581 1.6718373 1.5380313], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Creating tf dataset from tensor containing more than a element\n",
    "\n",
    "\n",
    "dataset=tf.data.Dataset.from_tensor_slices(tf.random.normal((4,5)))\n",
    "\n",
    "print(\"Creating dataset from tensor having more than a single element : \\n\", dataset)\n",
    "\n",
    "for element in dataset:\n",
    "    print(element)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset_from_tuple has 1 element.\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=3>)\n"
     ]
    }
   ],
   "source": [
    "## Creating dataset from tuple\n",
    "tuple_data=(1,2,3)\n",
    "dataset_from_tuple=tf.data.Dataset.from_tensors(tuple_data)\n",
    "\n",
    "\n",
    "print('The dataset_from_tuple has {} element.'.format(len(dataset_from_tuple)))\n",
    "\n",
    "for element in dataset_from_tuple:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of element in dataset_from_dict2 is 1.\n",
      "element =  {'a': <tf.Tensor: shape=(), dtype=int32, numpy=1>, 'b': <tf.Tensor: shape=(), dtype=int32, numpy=2>}\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dict_2={'a':1,'b':2} \n",
    "\n",
    "dataset_from_dict2=tf.data.Dataset.from_tensors(dict_2) # dict2 is counted as single element.\n",
    "print(\"Number of element in dataset_from_dict2 is {}.\".format(len(dataset_from_dict2)))\n",
    "\n",
    "for element in dataset_from_dict2:\n",
    "    print('element = ',element)\n",
    "    for value in element.values():\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: rank > 1 to create tf dataset using from_tensor_slices method \n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=5>, (<tf.Tensor: shape=(), dtype=string, numpy=b'a'>, <tf.Tensor: shape=(), dtype=string, numpy=b'b'>))\n",
      "dataset.as_numpy_iterator():  <tensorflow.python.data.ops.dataset_ops._NumpyIterator object at 0x00000153DE9B05E0>\n"
     ]
    }
   ],
   "source": [
    "## Nested tuple()\n",
    "\n",
    "nested_tuple=(5,('a','b'))\n",
    "try:\n",
    "    \n",
    "    dataset=tf.data.Dataset.from_tensor_slices(nested_tuple)\n",
    "   \n",
    "   \n",
    "except:\n",
    "    \n",
    "    dataset=tf.data.Dataset.from_tensors(nested_tuple)\n",
    "    print(\"Error: rank > 1 to create tf dataset using from_tensor_slices method \")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "for element in dataset:\n",
    "    print(element)\n",
    "\n",
    "\n",
    "print('dataset.as_numpy_iterator(): ', dataset.as_numpy_iterator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
      "array([ 0.03916196, -0.3756081 , -0.04804247,  1.5010437 , -0.3632689 ],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
      "\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "\n",
      "tf.Tensor([b'a'], shape=(1,), dtype=string)\n",
      "\n",
      "(<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
      "array([ 0.03916196, -0.3756081 , -0.04804247,  1.5010437 , -0.3632689 ],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
      "\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n",
      "\n",
      "tf.Tensor([b'b'], shape=(1,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "## Dataset with both features and labels\n",
    "f=[[1,2,3],[4,5,6]]\n",
    "l=[['a'],['b']]\n",
    "features=tf.data.Dataset.from_tensor_slices(f)\n",
    "labels=tf.data.Dataset.from_tensor_slices(l)\n",
    "\n",
    "#\n",
    "\n",
    "feature_labels=tf.data.Dataset.from_tensor_slices((f,l))\n",
    "\n",
    "for element_f,element_j in feature_labels:\n",
    "    print()\n",
    "    print(element)\n",
    "    print()\n",
    "    print(element_f)\n",
    "    print()\n",
    "    print(element_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from mnist dataset\n",
    "\n",
    "train_ds, test_ds=tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_ds=tf.data.Dataset.from_tensor_slices(train_ds)\n",
    "\n",
    "test_ds=tf.data.Dataset.from_tensor_slices(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next how to use map here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
