{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is it necessary to build tf pipeleine? I mean it is much easier just to train on numpy dataset. So, why use extra effort? \n",
    "\n",
    "==> Before, answering this we need to know what happens when we train data using numpy, then all of the data is loaded in to the memory directly.\n",
    "> In this scenario what happen if the training dataset is too large and can't fit into a memory? \n",
    "\n",
    "So, to handle this scenario tensorflow provides **tf.data** api which can handle large dataset. Using tf.data we can use dataset as iterator thus we don't need to load whole dataset within the memory. Beside handling large training dataset other advantages of using tf.data training pipeline are: \n",
    "\n",
    "1. Preprocessing during data. tf.data provides flexible way to preprocess dataset while training. Examples are if you are training images then you can do preprocessing steps such as rotation before training.\n",
    "2. tf.data provide consistent for working with different data types such as csv,images, video and so on.\n",
    "3. tf.data can also provide better compatibility with distributed training frameworks such as TensorFlow's tf.distribute API, which can help to scale training across multiple GPUs or machines.\n",
    "\n",
    "\n",
    " \n",
    " We usually use **tf.data.Dataset** method to handle tf data.  We will learn this in upcoming slides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.data dataset object are iterable in nature(similar to iterables and generators).Two of the most used method to create tf dataset are:\n",
    "\n",
    "- tf.data.Dataset.from_tensors: Creates a Dataset with a single element, comprising the given tensors. This method produces a dataset containing only a single element.\n",
    "\n",
    "- tf.data.Dataset.from_tensor_slices: Creates a Dataset whose elements are slices of the given tensors. The given tensors are sliced along their first dimension. This operation preserves the structure of the input tensors, removing the first dimension of each tensor and using it as the dataset dimension. All input tensors must have the same size in their first dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensors\n",
    "\n",
    "tensor1=tf.constant([1,2,3])\n",
    "tensor2=tf.constant([[1,2,3],[4,5,6]])\n",
    "tensor3=tf.Variable(tf.random.normal(shape=(10,3)))\n",
    "tensor4=tf.range(start=1,limit=11,delta=1)\n",
    "tensor5=tf.constant([[1,2,3]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len of dataset1 : 1\n",
      "len of dataset2 : 1\n",
      "len of the dataset3 : 1\n",
      "len of the dataset4 : 1\n",
      "len of the dataset5 : 1\n",
      "Len of labeled_dataset :  1\n",
      "\n",
      "dataset1\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "\n",
      "dataset2\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n",
      "\n",
      "dataset3\n",
      "tf.Tensor(\n",
      "[[-1.2151529  -0.9854829   0.09837101]\n",
      " [-0.53210956 -0.04680683 -0.7644955 ]\n",
      " [-0.34821305  0.2469302  -0.07629711]\n",
      " [ 0.01787011  0.02813985 -1.6390443 ]\n",
      " [-0.5280993  -0.84917665 -1.5853513 ]\n",
      " [ 1.2583779   0.4072297  -1.7567949 ]\n",
      " [ 1.7766263   0.6179925   0.48123974]\n",
      " [-1.2589386   0.7698292  -0.08977935]\n",
      " [ 0.4528408   0.01507247  0.03878821]\n",
      " [ 0.76816046  0.58638066  0.36378568]], shape=(10, 3), dtype=float32)\n",
      "\n",
      "dataset4\n",
      "tf.Tensor([ 1  2  3  4  5  6  7  8  9 10], shape=(10,), dtype=int32)\n",
      "\n",
      "dataset5\n",
      "tf.Tensor([[1 2 3]], shape=(1, 3), dtype=int32)\n",
      "Labeled Dataset\n",
      "(<tf.Tensor: shape=(10, 3), dtype=float32, numpy=\n",
      "array([[-1.2151529 , -0.9854829 ,  0.09837101],\n",
      "       [-0.53210956, -0.04680683, -0.7644955 ],\n",
      "       [-0.34821305,  0.2469302 , -0.07629711],\n",
      "       [ 0.01787011,  0.02813985, -1.6390443 ],\n",
      "       [-0.5280993 , -0.84917665, -1.5853513 ],\n",
      "       [ 1.2583779 ,  0.4072297 , -1.7567949 ],\n",
      "       [ 1.7766263 ,  0.6179925 ,  0.48123974],\n",
      "       [-1.2589386 ,  0.7698292 , -0.08977935],\n",
      "       [ 0.4528408 ,  0.01507247,  0.03878821],\n",
      "       [ 0.76816046,  0.58638066,  0.36378568]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])>)\n"
     ]
    }
   ],
   "source": [
    "# Creating different object of tf.data object using tf.data.Dataset.from_tensors\n",
    "\n",
    "dataset_1=tf.data.Dataset.from_tensors(tensor1) # from_tensors produces a dataset containing only a single element. To slice the input tensor into multiple elements\n",
    "dataset_2=tf.data.Dataset.from_tensors(tensor2)\n",
    "dataset_3=tf.data.Dataset.from_tensors(tensor3)\n",
    "dataset4=tf.data.Dataset.from_tensors(tensor4)\n",
    "dataset5=tf.data.Dataset.from_tensors(tensor5)\n",
    "labeled_dataset=tf.data.Dataset.from_tensors((tensor3,tensor4))\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print('len of dataset1 :',len(dataset_1))\n",
    "print('len of dataset2 :',len(dataset_2))\n",
    "print('len of the dataset3 :',len(dataset_3))\n",
    "print('len of the dataset4 :',len(dataset4))\n",
    "print('len of the dataset5 :',len(dataset5))\n",
    "print('Len of labeled_dataset : ', len(labeled_dataset))\n",
    "\n",
    "print()\n",
    "print('dataset1')\n",
    "for element in dataset_1:\n",
    "    print(element)\n",
    "\n",
    "print()\n",
    "print('dataset2')\n",
    "for element in dataset_2:\n",
    "    print(element)\n",
    "\n",
    "print()\n",
    "print('dataset3')\n",
    "for element in dataset_3:\n",
    "    print(element)\n",
    "\n",
    "print()\n",
    "print('dataset4')\n",
    "for element in dataset4:\n",
    "    print(element)\n",
    "\n",
    "print()\n",
    "print('dataset5')\n",
    "for element in dataset5:\n",
    "    print(element)\n",
    "\n",
    "print('Labeled Dataset')\n",
    "\n",
    "for element in labeled_dataset:\n",
    "    print(element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len of dataset1 : 3\n",
      "len of dataset2 : 2\n",
      "len of the dataset3 : 10\n",
      "len of the dataset4 : 10\n",
      "len of the dataset5 : 1\n",
      "len of the labeled_dataset : 10\n",
      "\n",
      "dataset1\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "\n",
      "dataset2\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n",
      "\n",
      "dataset3\n",
      "tf.Tensor([-1.2151529  -0.9854829   0.09837101], shape=(3,), dtype=float32)\n",
      "tf.Tensor([-0.53210956 -0.04680683 -0.7644955 ], shape=(3,), dtype=float32)\n",
      "tf.Tensor([-0.34821305  0.2469302  -0.07629711], shape=(3,), dtype=float32)\n",
      "tf.Tensor([ 0.01787011  0.02813985 -1.6390443 ], shape=(3,), dtype=float32)\n",
      "tf.Tensor([-0.5280993  -0.84917665 -1.5853513 ], shape=(3,), dtype=float32)\n",
      "tf.Tensor([ 1.2583779  0.4072297 -1.7567949], shape=(3,), dtype=float32)\n",
      "tf.Tensor([1.7766263  0.6179925  0.48123974], shape=(3,), dtype=float32)\n",
      "tf.Tensor([-1.2589386   0.7698292  -0.08977935], shape=(3,), dtype=float32)\n",
      "tf.Tensor([0.4528408  0.01507247 0.03878821], shape=(3,), dtype=float32)\n",
      "tf.Tensor([0.76816046 0.58638066 0.36378568], shape=(3,), dtype=float32)\n",
      "\n",
      "dataset4\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "\n",
      "dataset5\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "\n",
      "labeled Dataset\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-1.2151529 , -0.9854829 ,  0.09837101], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.53210956, -0.04680683, -0.7644955 ], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=2>)\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.34821305,  0.2469302 , -0.07629711], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=3>)\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 0.01787011,  0.02813985, -1.6390443 ], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=4>)\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.5280993 , -0.84917665, -1.5853513 ], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=5>)\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 1.2583779,  0.4072297, -1.7567949], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=6>)\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.7766263 , 0.6179925 , 0.48123974], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=7>)\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-1.2589386 ,  0.7698292 , -0.08977935], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=8>)\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.4528408 , 0.01507247, 0.03878821], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=9>)\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.76816046, 0.58638066, 0.36378568], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=10>)\n"
     ]
    }
   ],
   "source": [
    "# Creating Dataset using tf.data.Dataset.from_tensor_slices\n",
    "\n",
    "dataset_1=tf.data.Dataset.from_tensor_slices(tensor1) # from_tensors produces a dataset containing only a single element. To slice the input tensor into multiple elements\n",
    "dataset_2=tf.data.Dataset.from_tensor_slices(tensor2)\n",
    "dataset_3=tf.data.Dataset.from_tensor_slices(tensor3)\n",
    "dataset4=tf.data.Dataset.from_tensor_slices(tensor4)\n",
    "dataset5=tf.data.Dataset.from_tensor_slices(tensor5)\n",
    "labeled_dataset=tf.data.Dataset.from_tensor_slices((tensor3,tensor4))\n",
    "print()\n",
    "\n",
    "print('len of dataset1 :',len(dataset_1))\n",
    "print('len of dataset2 :',len(dataset_2))\n",
    "print('len of the dataset3 :',len(dataset_3))\n",
    "print('len of the dataset4 :',len(dataset4))\n",
    "print('len of the dataset5 :',len(dataset5))\n",
    "print('len of the labeled_dataset :',len(labeled_dataset))\n",
    "\n",
    "print()\n",
    "print('dataset1')\n",
    "for element in dataset_1:\n",
    "    print(element)\n",
    "\n",
    "print()\n",
    "print('dataset2')\n",
    "for element in dataset_2:\n",
    "    print(element)\n",
    "\n",
    "print()\n",
    "print('dataset3')\n",
    "for element in dataset_3:\n",
    "    print(element)\n",
    "\n",
    "print()\n",
    "print('dataset4')\n",
    "for element in dataset4:\n",
    "    print(element)\n",
    "\n",
    "print()\n",
    "print('dataset5')\n",
    "for element in dataset5:\n",
    "    print(element)\n",
    "\n",
    "print()\n",
    "print('labeled Dataset')\n",
    "\n",
    "for element in labeled_dataset:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature tf.Tensor([-1.2151529  -0.9854829   0.09837101], shape=(3,), dtype=float32)\n",
      "label  tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "## The labeled dataset itself contains two tensor features and label\n",
    "\n",
    "for feature, label in labeled_dataset:\n",
    "    print('feature', feature)\n",
    "    print('label ',label)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
