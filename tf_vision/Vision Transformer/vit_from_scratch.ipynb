{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "import cv2\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "h,w=x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x,y):\n",
    "\n",
    "   \n",
    "    x=tf.cast(x,dtype=tf.float32)\n",
    "    x=tf.divide(x,tf.constant(255.0))\n",
    "    x=tf.expand_dims(x,axis=-1) ## Add a channel layer\n",
    "    \n",
    "    y=tf.one_hot(y,depth=10)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting tf data pipeline \n",
    "\n",
    "batch_size=64\n",
    "\n",
    "train_dataset=tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "test_dataset=tf.data.Dataset.from_tensor_slices((x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQiklEQVR4nO3df5DU9X3H8edLOCEgRi4oJUoUkUSNNpjeoI5U7aQxxmkHnVYMk6TEGEmNxNqSjpa2kWZMh2QSU2KsU6wEsP7+NTAtNbFMqnGMxNOgosZfiBWEQ7wg+CNwHO/+sV8yJ95+7tjd213u83rM7Nze9/397vfNwovvd/fz3f0oIjCzwe+ARjdgZvXhsJtlwmE3y4TDbpYJh90sEw67WSYc9gxJ+l9JX6n3ttZYDvt+TNI6SX/c6D76S9I8SV2S3upxO7rRfeXCYbd6uz0iDupxW9vohnLhsA9CkkZL+k9Jr0v6TXH/iL1Wmyjpl5K2SVomqbXH9qdIeljSVklPSDqzrn8AGxAO++B0APBj4EjgI8C7wI/2WucvgC8D44BdwA8BJB0O/BdwNdAKfAO4W9Khfe1U0lRJW/tY7U8ldUp6WtIl/f4TWdUc9kEoIt6IiLsj4p2I2A58Gzhjr9Vuiog1EfE28I/AdElDgC8AKyJiRUTsjoj7gXbgnH7s96GIOCSxyh3AccChwMXANyXN2Oc/oFXEYR+EJI2Q9G+SXpG0DXgQOKQI8x6v9rj/CtACjKF0NnB+cQq/tThST6V0BlCViHgmIl6LiO6IeBhYAPx5tY9r/TO00Q3YgJgDfAw4OSI2SZoM/ApQj3XG97j/EaAL2ELpP4GbIuLiOvQZe/VkA8hH9v1fi6ThPW5DgVGUXqdvLd54u6qX7b4g6XhJI4BvAXdFRDfwH5ReV39G0pDiMc/s5Q2+fSZpWvHmoSRNAS4DllX7uNY/Dvv+bwWlYO+5zQP+BfgApSP1I8B9vWx3E7AY2AQMpxQ8IuJVYBowF3id0pH+b+nHvxVJfyjprcQqnwNeBLYDS4HvRMSSvh7XakP+8gqzPPjIbpYJh90sEw67WSYcdrNM1HWc/UANi+GMrOcuzbLyW95mZ+zo9dqFqsIu6WxKV0ENAf49Iuan1h/OSE7Wp6rZpZklrIqVZWsVn8YXl15eB3wWOB6YIen4Sh/PzAZWNa/ZpwAvRsTaiNgJ3EbpYgwza0LVhP1w3vthivXFsveQNEtSu6T2LnZUsTszq8aAvxsfEQsjoi0i2loYNtC7M7Myqgn7Bt77yakjimVm1oSqCfujwCRJEyQdSOlDDstr05aZ1VrFQ28RsUvSbOAnlIbeFkXE0zXrzMxqqqpx9ohYQekjlmbW5Hy5rFkmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZaKqWVyt+Wlo+q94yKFjBnT/z33jqLK17hG7k9seOXFzsj7ia0rWN11zYNna4223J7fd0v12sn7ynXOS9WP+5pFkvRGqCrukdcB2oBvYFRFttWjKzGqvFkf2P4qILTV4HDMbQH7NbpaJasMewE8lPSZpVm8rSJolqV1Sexc7qtydmVWq2tP4qRGxQdJhwP2Sfh0RD/ZcISIWAgsBDlZrVLk/M6tQVUf2iNhQ/NwM3AtMqUVTZlZ7FYdd0khJo/bcB84C1tSqMTOrrWpO48cC90ra8zi3RMR9NelqkBly3KRkPYa1JOuvnXFIsv7uKeXHhFs/mB4v/vkn0uPNjfTf74xK1r/zo7OT9VUn3lK29nLXu8lt53d8Oln/8M/3v1ekFYc9ItYCn6hhL2Y2gDz0ZpYJh90sEw67WSYcdrNMOOxmmfBHXGug+8xPJuvXLL4uWf9oS/mPYg5mXdGdrH/z2i8l60PfTg9/nXrn7LK1URt2JbcdtiU9NDeifVWy3ox8ZDfLhMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMuFx9hoY9txryfpjvx2frH+0paOW7dTUnI2nJOtr30p/FfXiiXeVrb25Oz1OPvaHDyfrA2n/+wBr33xkN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0yoYj6jSgerNY4WZ+q2/6aReeFpybr285Of93zkCcPStaf+Nq1+9zTHldv+f1k/dEz0uPo3VvfTNbj1PJfQLzusuSmTJjxRHoFe59VsZJt0dnrXNY+sptlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmfA4exMYMuZDyXr3G53J+su3lB8rf/r0Rcltp/zz15P1w65r3GfKbd9VNc4uaZGkzZLW9FjWKul+SS8UP0fXsmEzq73+nMYvBvae9f5KYGVETAJWFr+bWRPrM+wR8SCw93nkNGBJcX8JcG5t2zKzWqv0O+jGRsTG4v4mYGy5FSXNAmYBDGdEhbszs2pV/W58lN7hK/suX0QsjIi2iGhrYVi1uzOzClUa9g5J4wCKn5tr15KZDYRKw74cmFncnwksq007ZjZQ+nzNLulW4ExgjKT1wFXAfOAOSRcBrwDTB7LJwa57yxtVbd+1rfL53T/++WeS9devH5J+gN3pOdatefQZ9oiYUabkq2PM9iO+XNYsEw67WSYcdrNMOOxmmXDYzTLhKZsHgeOueL5s7cIT04MmPz5yZbJ+xvmXJuujbn8kWbfm4SO7WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJj7MPAqlpk9+45Ljktv+3/N1k/cqrlybrfzf9vGQ9fvXBsrXx3/5Fclvq+DXnOfCR3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhKdszlznl09N1m++6nvJ+oShwyve98eXzk7WJ92wMVnftXZdxfserKqastnMBgeH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XC4+yWFKdNTtYPnr8+Wb/16J9UvO9jf/aVZP1j/1T+c/wA3S+srXjf+6uqxtklLZK0WdKaHsvmSdogaXVxO6eWDZtZ7fXnNH4xcHYvy38QEZOL24ratmVmtdZn2CPiQaCzDr2Y2QCq5g262ZKeLE7zR5dbSdIsSe2S2rvYUcXuzKwalYb9emAiMBnYCHy/3IoRsTAi2iKirYVhFe7OzKpVUdgjoiMiuiNiN3ADMKW2bZlZrVUUdknjevx6HrCm3Lpm1hz6HGeXdCtwJjAG6ACuKn6fDASwDvhqRKQ/fIzH2QejIWMPS9Zfu+CYsrVVVyxIbntAH8eiz798VrL+5tQ3kvXBKDXO3uckERExo5fFN1bdlZnVlS+XNcuEw26WCYfdLBMOu1kmHHazTPgjrtYwd6xPT9k8Qgcm6+/EzmT9T75+efnHvndVctv9lb9K2swcdrNcOOxmmXDYzTLhsJtlwmE3y4TDbpaJPj/1ZnnbPXVysv7S+ekpm0+YvK5sra9x9L5c23lSsj5iWXtVjz/Y+MhulgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XC4+yDnNpOSNafvyw91n3DaUuS9dOHpz9TXo0d0ZWsP9I5If0Au/v8dvOs+MhulgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2Wiz3F2SeOBpcBYSlM0L4yIBZJagduBoyhN2zw9In4zcK3ma+iEI5P1ly78cNnavAtuS277ZwdtqainWpjb0ZasP7DglGR99JL0987be/XnyL4LmBMRxwOnAJdKOh64ElgZEZOAlcXvZtak+gx7RGyMiMeL+9uBZ4HDgWnAnsurlgDnDlCPZlYD+/SaXdJRwEnAKmBsROy5HnETpdN8M2tS/Q67pIOAu4HLI2Jbz1qUJozrddI4SbMktUtq72JHVc2aWeX6FXZJLZSCfnNE3FMs7pA0rqiPAzb3tm1ELIyItohoa2FYLXo2swr0GXZJAm4Eno2Ia3qUlgMzi/szgWW1b8/MaqU/H3E9Dfgi8JSk1cWyucB84A5JFwGvANMHpMNBYOhRH0nW3/yDccn6Bd+6L1n/y0PuSdYH0pyN6eGxX/xr+eG11sW/TG47ereH1mqpz7BHxENAr/M9A55s3Ww/4SvozDLhsJtlwmE3y4TDbpYJh90sEw67WSb8VdL9NHTc75WtdS4amdz2kgkPJOszRnVU1FMtzN4wNVl//PrJyfqYu9Yk663bPVbeLHxkN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0ykc04+87PpL+2eOdfdybrc49ZUbZ21gferqinWunofrds7fTlc5LbHvsPv07WW7emx8l3J6vWTHxkN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0ykc04+7pz0/+vPX/inQO27+u2TkzWFzxwVrKu7nLf5F1y7NUvl61N6liV3LY7WbXBxEd2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTioj0CtJ4YCkwFghgYUQskDQPuBh4vVh1bkSU/9A3cLBa42R5lmezgbIqVrItOnu9MKM/F9XsAuZExOOSRgGPSbq/qP0gIr5Xq0bNbOD0GfaI2AhsLO5vl/QscPhAN2ZmtbVPr9klHQWcBOy5BnO2pCclLZI0usw2syS1S2rvYkd13ZpZxfoddkkHAXcDl0fENuB6YCIwmdKR//u9bRcRCyOiLSLaWhhWfcdmVpF+hV1SC6Wg3xwR9wBEREdEdEfEbuAGYMrAtWlm1eoz7JIE3Ag8GxHX9Fg+rsdq5wHp6TzNrKH68278acAXgackrS6WzQVmSJpMaThuHfDVAejPzGqkP+/GPwT0Nm6XHFM3s+biK+jMMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJvr8Kuma7kx6HXilx6IxwJa6NbBvmrW3Zu0L3FulatnbkRFxaG+Fuob9fTuX2iOirWENJDRrb83aF7i3StWrN5/Gm2XCYTfLRKPDvrDB+09p1t6atS9wb5WqS28Nfc1uZvXT6CO7mdWJw26WiYaEXdLZkp6T9KKkKxvRQzmS1kl6StJqSe0N7mWRpM2S1vRY1irpfkkvFD97nWOvQb3Nk7SheO5WSzqnQb2Nl/QzSc9IelrSXxXLG/rcJfqqy/NW99fskoYAzwOfBtYDjwIzIuKZujZShqR1QFtENPwCDEmnA28BSyPihGLZd4HOiJhf/Ec5OiKuaJLe5gFvNXoa72K2onE9pxkHzgW+RAOfu0Rf06nD89aII/sU4MWIWBsRO4HbgGkN6KPpRcSDQOdei6cBS4r7Syj9Y6m7Mr01hYjYGBGPF/e3A3umGW/oc5foqy4aEfbDgVd7/L6e5prvPYCfSnpM0qxGN9OLsRGxsbi/CRjbyGZ60ec03vW01zTjTfPcVTL9ebX8Bt37TY2ITwKfBS4tTlebUpRegzXT2Gm/pvGul16mGf+dRj53lU5/Xq1GhH0DML7H70cUy5pCRGwofm4G7qX5pqLu2DODbvFzc4P7+Z1mmsa7t2nGaYLnrpHTnzci7I8CkyRNkHQg8DlgeQP6eB9JI4s3TpA0EjiL5puKejkws7g/E1jWwF7eo1mm8S43zTgNfu4aPv15RNT9BpxD6R35l4C/b0QPZfo6GniiuD3d6N6AWymd1nVRem/jIuBDwErgBeB/gNYm6u0m4CngSUrBGteg3qZSOkV/Elhd3M5p9HOX6Ksuz5svlzXLhN+gM8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0y8f9ztSMbyx9e9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualiszing the dataset\n",
    "for image,label in train_dataset.take(1):\n",
    "    image=image.numpy().reshape(28,28)\n",
    "    label=label.numpy()\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'Label : {label}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "\n",
    "train_dataset=(train_dataset.shuffle(buffer_size=1000,reshuffle_each_iteration=True)\n",
    "                .map(preprocess)\n",
    "                .batch(batch_size=batch_size,drop_remainder=True)\n",
    "                .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "test_dataset=(test_dataset.map(preprocess)\n",
    "                .batch(batch_size=batch_size,drop_remainder=True)\n",
    "                .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of patches in an image : 196.0\n"
     ]
    }
   ],
   "source": [
    "## Creating Patches\n",
    "\n",
    "patch_size=4\n",
    "num_patches=h*w/patch_size\n",
    "print(f'Num of patches in an image : {num_patches}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patch(tf.keras.layers.Layer):\n",
    "    def __init__(self,patch_size=4):\n",
    "        super(Patch,self).__init__()\n",
    "        self.patch_size=patch_size\n",
    "       \n",
    "\n",
    "       \n",
    "    def call(self,images):\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding='VALID'\n",
    "            )\n",
    "        \n",
    "        return patches ## pathces.shape ==> batch_size,num_patch_row,num_patch_column,flatten_patch(example: 4*4=16 flatten dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,_ in train_dataset.take(1):\n",
    "    patches=Patch(patch_size)(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 7, 7, 16])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches[0][0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining a function to draw the number of patches \n",
    "\n",
    "def plot_patches(patch_batch):\n",
    "\n",
    "    nrows=patch_batch.shape[1]\n",
    "    ncols=patch_batch.shape[2]\n",
    "    random_patch=tf.random.shuffle(patch_batch)[0].numpy()\n",
    "\n",
    "    ## creating subplots\n",
    "\n",
    "    fig,axes=plt.subplots(nrows=nrows,ncols=ncols)\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "\n",
    "\n",
    "    for i in range(random_patch.shape[0]):\n",
    "        for j in range(random_patch.shape[1]):\n",
    "            patch_img=random_patch[i,j].reshape(patch_size,patch_size,1)\n",
    "            axes[i][j].imshow(patch_img)\n",
    "            axes[i][j].axis('off')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 49 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_patches(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 7, 7, 16])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 28, 28, 1])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# d_model=256\n",
    "\n",
    "# class PatchEmbedding(tf.keras.layers.Layer):\n",
    "#     def __init__(self,d_model):\n",
    "#         super(PatchEmbedding,self).__init__()\n",
    "#         self.patch=Patch()\n",
    "#         self.d_model=d_model\n",
    "#         self.projection_layer=tf.keras.layers.Dense(self.d_model)\n",
    "#         self.embedding=tf.keras.layers.Embedding(input_dim=self.d_model*2,output_dim=self.d_model)\n",
    "       \n",
    "        \n",
    "    \n",
    "\n",
    "#     def call(self,images):\n",
    "\n",
    "#         patches=self.patch(images)\n",
    "\n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "#         num_patches,flatten_patches=self.patches_transform(patches=patches)\n",
    "        \n",
    "#         projected_patches=self.projection_layer(flatten_patches)\n",
    "#         positional_embedding=tf.expand_dims(self.embedding(tf.range(num_patches)),axis=0)\n",
    "\n",
    "       \n",
    "        \n",
    "       \n",
    "       \n",
    "#         patch_embedding=tf.add(projected_patches,positional_embedding)\n",
    "        \n",
    "#         return patch_embedding\n",
    "    \n",
    "#     def patches_transform(self,patches):\n",
    "#         num_patches=tf.multiply(patches.shape[1],patches.shape[2])\n",
    "        \n",
    "#         last_dim=patches.shape[-1]\n",
    "#         flatten_patches=tf.reshape(patches,[-1,num_patches,last_dim])\n",
    "#         return num_patches,flatten_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model=256\n",
    "\n",
    "class PatchEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model):\n",
    "        super(PatchEmbedding, self).__init__()\n",
    "        self.patch = Patch()\n",
    "        self.d_model = d_model\n",
    "        self.projection_layer = tf.keras.layers.Dense(self.d_model)\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.d_model*2, output_dim=self.d_model)\n",
    "        \n",
    "        # Initialize the class token. Note that we use tf.Variable with trainable=True to make sure it's trainable\n",
    "        self.class_token = tf.Variable(initial_value=tf.zeros(shape=(1, 1, self.d_model)), trainable=True)\n",
    "\n",
    "    def call(self, images):\n",
    "        patches = self.patch(images)\n",
    "\n",
    "        num_patches, flatten_patches = self.patches_transform(patches=patches)\n",
    "        \n",
    "        projected_patches = self.projection_layer(flatten_patches)\n",
    "        \n",
    "        # This line was added to repeat the class token for each image in the batch and add it to the beginning of projected_patches\n",
    "        class_tokens = tf.repeat(self.class_token, repeats=tf.shape(images)[0], axis=0) ## tokenizer\n",
    "        projected_patches = tf.concat([class_tokens, projected_patches], axis=1)\n",
    "        \n",
    "        positional_embedding = tf.expand_dims(self.embedding(tf.range(num_patches + 1)), axis=0)  # +1 for the class token\n",
    "        patch_embedding = tf.add(projected_patches, positional_embedding)\n",
    "        \n",
    "        return patch_embedding\n",
    "    \n",
    "    def patches_transform(self, patches):\n",
    "        num_patches = tf.multiply(patches.shape[1], patches.shape[2])\n",
    "        last_dim = patches.shape[-1]\n",
    "        flatten_patches = tf.reshape(patches, [-1, num_patches, last_dim])\n",
    "        return num_patches, flatten_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 50, 256)\n"
     ]
    }
   ],
   "source": [
    "patch_out=PatchEmbedding(d_model=d_model)(image)\n",
    "print(patch_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Encoder for Vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the parameters of Encoder\n",
    "\n",
    "num_heads=4\n",
    "d_model=d_model\n",
    "dff=d_model*3\n",
    "dropout_rate=0.3\n",
    "\n",
    "\n",
    "def FFN(d_model,dff,droput_rate):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=dff,activation=tf.nn.gelu),\n",
    "        tf.keras.layers.Dense(units=d_model),\n",
    "        tf.keras.layers.Dropout(rate=dropout_rate)\n",
    "    ])\n",
    "\n",
    "\n",
    "class Encoder_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model,dff,dropout_rate,num_heads):\n",
    "        super(Encoder_Layer,self).__init__()\n",
    "        self.mha=tf.keras.layers.MultiHeadAttention(num_heads=num_heads,\n",
    "                                                   key_dim=d_model,\n",
    "                                                   dropout=dropout_rate)\n",
    "        self.add_1=tf.keras.layers.Add()\n",
    "        self.layer_norm_1=tf.keras.layers.LayerNormalization()\n",
    "        self.add_2=tf.keras.layers.Add()\n",
    "        self.layer_norm_2=tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "        self.ffn=FFN(d_model,dff,dropout_rate)\n",
    "        \n",
    "        self.attn_score=None\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        \n",
    "        attn_output,self.attn_score=self.mha(query=inputs,\n",
    "                                             value=inputs,\n",
    "                                             key=inputs,\n",
    "                                             return_attention_scores=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        x=self.layer_norm_1(self.add_1([inputs,attn_output]))\n",
    "        x=self.ffn(x)\n",
    "        final_output=self.layer_norm_2(self.add_2([x,attn_output]))\n",
    "        return final_output\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_layer=Encoder_Layer(d_model,dff,dropout_rate,num_heads)\n",
    "enc_lay_output=enc_layer(patch_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 12800), dtype=float32, numpy=\n",
       "array([[-1.9669405 ,  0.98619956,  0.76074624, ...,  1.3083854 ,\n",
       "         0.65041447, -0.83671755],\n",
       "       [-1.9665837 ,  0.99678785,  0.7699859 , ...,  1.3120441 ,\n",
       "         0.6605691 , -0.8465196 ],\n",
       "       [-1.9732773 ,  0.95694876,  0.83389896, ...,  1.323069  ,\n",
       "         0.6460548 , -0.84978753],\n",
       "       ...,\n",
       "       [-1.9505055 ,  1.0181787 ,  0.7392138 , ...,  1.2981161 ,\n",
       "         0.6368705 , -0.80871236],\n",
       "       [-2.0534952 ,  0.87191206,  0.9064809 , ...,  1.3360757 ,\n",
       "         0.64271706, -0.9888132 ],\n",
       "       [-2.062455  ,  0.8790412 ,  0.9246457 , ...,  1.330889  ,\n",
       "         0.69197667, -0.9247396 ]], dtype=float32)>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Flatten()(enc_lay_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 4, 49, 49), dtype=float32, numpy=\n",
       "array([[[[0.02040814, 0.0204078 , 0.02040799, ..., 0.02040822,\n",
       "          0.02040782, 0.02040777],\n",
       "         [0.0204082 , 0.02040812, 0.02040796, ..., 0.02040818,\n",
       "          0.02040811, 0.02040824],\n",
       "         [0.02040828, 0.02040847, 0.02040843, ..., 0.02040826,\n",
       "          0.02040841, 0.02040841],\n",
       "         ...,\n",
       "         [0.02040799, 0.02040761, 0.02040732, ..., 0.02040777,\n",
       "          0.0204075 , 0.02040753],\n",
       "         [0.02040849, 0.0204083 , 0.02040858, ..., 0.02040863,\n",
       "          0.02040852, 0.02040823],\n",
       "         [0.02040809, 0.02040829, 0.02040817, ..., 0.02040775,\n",
       "          0.02040809, 0.02040832]],\n",
       "\n",
       "        [[0.020408  , 0.02040822, 0.02040833, ..., 0.02040822,\n",
       "          0.02040838, 0.02040818],\n",
       "         [0.02040855, 0.02040836, 0.02040833, ..., 0.02040885,\n",
       "          0.02040844, 0.02040844],\n",
       "         [0.02040767, 0.0204077 , 0.02040757, ..., 0.02040842,\n",
       "          0.02040764, 0.02040766],\n",
       "         ...,\n",
       "         [0.02040867, 0.02040763, 0.02040902, ..., 0.02040908,\n",
       "          0.02040885, 0.02040845],\n",
       "         [0.02040789, 0.02040803, 0.02040828, ..., 0.02040779,\n",
       "          0.02040808, 0.02040822],\n",
       "         [0.02040815, 0.02040811, 0.02040793, ..., 0.02040797,\n",
       "          0.02040795, 0.02040831]],\n",
       "\n",
       "        [[0.02040788, 0.02040839, 0.02040823, ..., 0.02040803,\n",
       "          0.02040844, 0.02040852],\n",
       "         [0.02040815, 0.02040836, 0.02040844, ..., 0.0204079 ,\n",
       "          0.02040819, 0.02040821],\n",
       "         [0.02040801, 0.02040792, 0.02040804, ..., 0.0204084 ,\n",
       "          0.02040803, 0.02040816],\n",
       "         ...,\n",
       "         [0.02040806, 0.02040774, 0.02040804, ..., 0.0204064 ,\n",
       "          0.02040805, 0.02040801],\n",
       "         [0.02040821, 0.02040804, 0.02040831, ..., 0.02040775,\n",
       "          0.02040815, 0.02040824],\n",
       "         [0.02040835, 0.0204083 , 0.02040853, ..., 0.02040819,\n",
       "          0.02040839, 0.02040849]],\n",
       "\n",
       "        [[0.02040796, 0.02040814, 0.02040818, ..., 0.02040787,\n",
       "          0.02040796, 0.020408  ],\n",
       "         [0.02040823, 0.02040816, 0.02040809, ..., 0.02040817,\n",
       "          0.02040819, 0.02040824],\n",
       "         [0.02040813, 0.02040833, 0.02040826, ..., 0.02040865,\n",
       "          0.02040835, 0.02040859],\n",
       "         ...,\n",
       "         [0.02040799, 0.02040803, 0.02040765, ..., 0.02040756,\n",
       "          0.02040653, 0.02040711],\n",
       "         [0.02040827, 0.02040825, 0.02040828, ..., 0.02040818,\n",
       "          0.0204082 , 0.02040822],\n",
       "         [0.02040856, 0.02040835, 0.02040847, ..., 0.02040857,\n",
       "          0.02040852, 0.02040846]]],\n",
       "\n",
       "\n",
       "       [[[0.02040806, 0.02040772, 0.02040791, ..., 0.0204077 ,\n",
       "          0.02040774, 0.02040769],\n",
       "         [0.02040814, 0.02040806, 0.0204079 , ..., 0.02040824,\n",
       "          0.02040805, 0.02040819],\n",
       "         [0.02040843, 0.02040862, 0.02040857, ..., 0.02040856,\n",
       "          0.02040856, 0.02040856],\n",
       "         ...,\n",
       "         [0.02040858, 0.02040835, 0.02040856, ..., 0.02040854,\n",
       "          0.02040847, 0.02040846],\n",
       "         [0.02040859, 0.0204084 , 0.02040868, ..., 0.02040867,\n",
       "          0.02040861, 0.02040833],\n",
       "         [0.02040823, 0.02040843, 0.02040831, ..., 0.02040835,\n",
       "          0.02040823, 0.02040847]],\n",
       "\n",
       "        [[0.02040803, 0.02040825, 0.02040836, ..., 0.02040837,\n",
       "          0.0204084 , 0.02040821],\n",
       "         [0.02040868, 0.02040848, 0.02040846, ..., 0.02040855,\n",
       "          0.02040857, 0.02040857],\n",
       "         [0.0204073 , 0.02040734, 0.0204072 , ..., 0.0204073 ,\n",
       "          0.02040727, 0.02040729],\n",
       "         ...,\n",
       "         [0.02040826, 0.020408  , 0.02040831, ..., 0.02040828,\n",
       "          0.02040807, 0.02040811],\n",
       "         [0.02040792, 0.02040805, 0.02040831, ..., 0.02040795,\n",
       "          0.02040811, 0.02040824],\n",
       "         [0.02040813, 0.02040809, 0.02040791, ..., 0.02040794,\n",
       "          0.02040793, 0.0204083 ]],\n",
       "\n",
       "        [[0.02040804, 0.02040855, 0.0204084 , ..., 0.02040884,\n",
       "          0.02040861, 0.02040868],\n",
       "         [0.02040811, 0.02040832, 0.02040841, ..., 0.02040838,\n",
       "          0.02040816, 0.02040818],\n",
       "         [0.02040798, 0.02040787, 0.020408  , ..., 0.02040804,\n",
       "          0.02040799, 0.02040813],\n",
       "         ...,\n",
       "         [0.02040822, 0.02040848, 0.02040854, ..., 0.02040819,\n",
       "          0.02040837, 0.02040827],\n",
       "         [0.02040826, 0.02040809, 0.02040837, ..., 0.02040799,\n",
       "          0.02040821, 0.02040829],\n",
       "         [0.02040847, 0.02040842, 0.02040865, ..., 0.02040879,\n",
       "          0.02040851, 0.02040861]],\n",
       "\n",
       "        [[0.02040793, 0.02040811, 0.02040814, ..., 0.02040806,\n",
       "          0.02040793, 0.02040797],\n",
       "         [0.02040817, 0.0204081 , 0.02040803, ..., 0.02040813,\n",
       "          0.02040813, 0.02040818],\n",
       "         [0.02040823, 0.02040844, 0.02040836, ..., 0.02040861,\n",
       "          0.02040845, 0.02040869],\n",
       "         ...,\n",
       "         [0.02040833, 0.02040832, 0.0204083 , ..., 0.02040835,\n",
       "          0.02040832, 0.02040817],\n",
       "         [0.02040835, 0.02040833, 0.02040837, ..., 0.0204083 ,\n",
       "          0.02040828, 0.02040831],\n",
       "         [0.02040867, 0.02040847, 0.02040859, ..., 0.02040863,\n",
       "          0.02040864, 0.02040858]]],\n",
       "\n",
       "\n",
       "       [[[0.02040816, 0.02040782, 0.02040801, ..., 0.0204078 ,\n",
       "          0.02040784, 0.02040779],\n",
       "         [0.02040813, 0.02040805, 0.02040789, ..., 0.02040824,\n",
       "          0.02040804, 0.02040818],\n",
       "         [0.02040832, 0.02040851, 0.02040847, ..., 0.02040846,\n",
       "          0.02040845, 0.02040845],\n",
       "         ...,\n",
       "         [0.02040846, 0.02040823, 0.02040844, ..., 0.02040841,\n",
       "          0.02040835, 0.02040835],\n",
       "         [0.02040851, 0.02040832, 0.02040859, ..., 0.02040858,\n",
       "          0.02040853, 0.02040824],\n",
       "         [0.02040816, 0.02040837, 0.02040825, ..., 0.02040829,\n",
       "          0.02040816, 0.0204084 ]],\n",
       "\n",
       "        [[0.02040794, 0.02040817, 0.02040827, ..., 0.02040828,\n",
       "          0.02040832, 0.02040812],\n",
       "         [0.02040855, 0.02040836, 0.02040834, ..., 0.02040843,\n",
       "          0.02040845, 0.02040845],\n",
       "         [0.02040758, 0.02040761, 0.02040748, ..., 0.02040757,\n",
       "          0.02040755, 0.02040757],\n",
       "         ...,\n",
       "         [0.02040828, 0.02040802, 0.02040833, ..., 0.0204083 ,\n",
       "          0.02040809, 0.02040813],\n",
       "         [0.02040798, 0.02040812, 0.02040837, ..., 0.02040802,\n",
       "          0.02040817, 0.02040831],\n",
       "         [0.02040816, 0.02040812, 0.02040794, ..., 0.02040797,\n",
       "          0.02040796, 0.02040832]],\n",
       "\n",
       "        [[0.02040794, 0.02040846, 0.0204083 , ..., 0.02040874,\n",
       "          0.02040851, 0.02040859],\n",
       "         [0.02040806, 0.02040827, 0.02040836, ..., 0.02040833,\n",
       "          0.0204081 , 0.02040813],\n",
       "         [0.02040803, 0.02040793, 0.02040805, ..., 0.02040809,\n",
       "          0.02040804, 0.02040818],\n",
       "         ...,\n",
       "         [0.02040821, 0.02040847, 0.02040853, ..., 0.02040818,\n",
       "          0.02040836, 0.02040826],\n",
       "         [0.02040828, 0.02040811, 0.02040839, ..., 0.02040801,\n",
       "          0.02040823, 0.02040831],\n",
       "         [0.02040832, 0.02040827, 0.0204085 , ..., 0.02040865,\n",
       "          0.02040836, 0.02040847]],\n",
       "\n",
       "        [[0.02040794, 0.02040812, 0.02040815, ..., 0.02040808,\n",
       "          0.02040794, 0.02040798],\n",
       "         [0.02040818, 0.02040811, 0.02040804, ..., 0.02040814,\n",
       "          0.02040814, 0.02040819],\n",
       "         [0.02040813, 0.02040834, 0.02040826, ..., 0.02040852,\n",
       "          0.02040835, 0.0204086 ],\n",
       "         ...,\n",
       "         [0.02040834, 0.02040833, 0.0204083 , ..., 0.02040835,\n",
       "          0.02040833, 0.02040819],\n",
       "         [0.02040831, 0.02040828, 0.02040832, ..., 0.02040825,\n",
       "          0.02040824, 0.02040826],\n",
       "         [0.02040854, 0.02040834, 0.02040845, ..., 0.0204085 ,\n",
       "          0.02040851, 0.02040845]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.02040816, 0.02040781, 0.020408  , ..., 0.0204078 ,\n",
       "          0.02040783, 0.02040778],\n",
       "         [0.02040821, 0.02040813, 0.02040796, ..., 0.02040831,\n",
       "          0.02040812, 0.02040825],\n",
       "         [0.0204083 , 0.02040849, 0.02040844, ..., 0.02040843,\n",
       "          0.02040843, 0.02040843],\n",
       "         ...,\n",
       "         [0.0204084 , 0.02040818, 0.02040838, ..., 0.02040836,\n",
       "          0.0204083 , 0.02040829],\n",
       "         [0.02040846, 0.02040827, 0.02040855, ..., 0.02040854,\n",
       "          0.02040848, 0.0204082 ],\n",
       "         [0.02040814, 0.02040834, 0.02040822, ..., 0.02040826,\n",
       "          0.02040814, 0.02040837]],\n",
       "\n",
       "        [[0.020408  , 0.02040822, 0.02040833, ..., 0.02040834,\n",
       "          0.02040838, 0.02040818],\n",
       "         [0.02040854, 0.02040835, 0.02040832, ..., 0.02040841,\n",
       "          0.02040843, 0.02040843],\n",
       "         [0.02040763, 0.02040766, 0.02040753, ..., 0.02040763,\n",
       "          0.0204076 , 0.02040762],\n",
       "         ...,\n",
       "         [0.02040818, 0.02040792, 0.02040823, ..., 0.02040819,\n",
       "          0.02040798, 0.02040802],\n",
       "         [0.02040793, 0.02040807, 0.02040832, ..., 0.02040797,\n",
       "          0.02040812, 0.02040826],\n",
       "         [0.02040816, 0.02040812, 0.02040794, ..., 0.02040796,\n",
       "          0.02040795, 0.02040832]],\n",
       "\n",
       "        [[0.02040788, 0.02040839, 0.02040824, ..., 0.02040868,\n",
       "          0.02040845, 0.02040852],\n",
       "         [0.02040811, 0.02040832, 0.0204084 , ..., 0.02040838,\n",
       "          0.02040815, 0.02040818],\n",
       "         [0.02040803, 0.02040793, 0.02040805, ..., 0.0204081 ,\n",
       "          0.02040804, 0.02040818],\n",
       "         ...,\n",
       "         [0.02040815, 0.02040841, 0.02040847, ..., 0.02040812,\n",
       "          0.0204083 , 0.0204082 ],\n",
       "         [0.02040822, 0.02040805, 0.02040833, ..., 0.02040795,\n",
       "          0.02040816, 0.02040825],\n",
       "         [0.02040835, 0.0204083 , 0.02040853, ..., 0.02040867,\n",
       "          0.02040839, 0.02040849]],\n",
       "\n",
       "        [[0.02040799, 0.02040817, 0.02040821, ..., 0.02040813,\n",
       "          0.02040799, 0.02040803],\n",
       "         [0.02040817, 0.02040809, 0.02040803, ..., 0.02040813,\n",
       "          0.02040812, 0.02040818],\n",
       "         [0.02040818, 0.02040839, 0.02040831, ..., 0.02040857,\n",
       "          0.0204084 , 0.02040864],\n",
       "         ...,\n",
       "         [0.02040826, 0.02040825, 0.02040823, ..., 0.02040827,\n",
       "          0.02040826, 0.02040811],\n",
       "         [0.02040828, 0.02040825, 0.02040829, ..., 0.02040822,\n",
       "          0.02040821, 0.02040823],\n",
       "         [0.02040857, 0.02040836, 0.02040848, ..., 0.02040852,\n",
       "          0.02040854, 0.02040847]]],\n",
       "\n",
       "\n",
       "       [[[0.02040819, 0.02040785, 0.02040804, ..., 0.02040794,\n",
       "          0.02040787, 0.02040782],\n",
       "         [0.02040819, 0.02040811, 0.02040794, ..., 0.02040826,\n",
       "          0.02040809, 0.02040823],\n",
       "         [0.02040817, 0.02040836, 0.02040832, ..., 0.02040832,\n",
       "          0.0204083 , 0.0204083 ],\n",
       "         ...,\n",
       "         [0.0204083 , 0.02040808, 0.02040827, ..., 0.02040822,\n",
       "          0.02040826, 0.02040821],\n",
       "         [0.02040838, 0.02040819, 0.02040847, ..., 0.02040853,\n",
       "          0.0204084 , 0.02040811],\n",
       "         [0.02040808, 0.02040828, 0.02040816, ..., 0.02040813,\n",
       "          0.02040808, 0.02040832]],\n",
       "\n",
       "        [[0.020408  , 0.02040823, 0.02040833, ..., 0.02040826,\n",
       "          0.02040837, 0.02040818],\n",
       "         [0.02040845, 0.02040826, 0.02040823, ..., 0.02040842,\n",
       "          0.02040834, 0.02040834],\n",
       "         [0.02040782, 0.02040785, 0.02040772, ..., 0.02040783,\n",
       "          0.02040779, 0.02040781],\n",
       "         ...,\n",
       "         [0.02040831, 0.02040791, 0.02040837, ..., 0.02040826,\n",
       "          0.02040806, 0.02040811],\n",
       "         [0.02040791, 0.02040805, 0.0204083 , ..., 0.02040792,\n",
       "          0.0204081 , 0.02040824],\n",
       "         [0.02040814, 0.0204081 , 0.02040792, ..., 0.02040795,\n",
       "          0.02040794, 0.0204083 ]],\n",
       "\n",
       "        [[0.02040786, 0.02040837, 0.02040822, ..., 0.02040857,\n",
       "          0.02040843, 0.0204085 ],\n",
       "         [0.02040805, 0.02040826, 0.02040835, ..., 0.02040826,\n",
       "          0.02040809, 0.02040812],\n",
       "         [0.02040806, 0.02040796, 0.02040809, ..., 0.0204082 ,\n",
       "          0.02040807, 0.02040821],\n",
       "         ...,\n",
       "         [0.02040818, 0.02040838, 0.02040845, ..., 0.02040813,\n",
       "          0.02040835, 0.02040819],\n",
       "         [0.02040827, 0.0204081 , 0.02040838, ..., 0.02040795,\n",
       "          0.02040822, 0.0204083 ],\n",
       "         [0.02040826, 0.0204082 , 0.02040843, ..., 0.0204085 ,\n",
       "          0.02040829, 0.0204084 ]],\n",
       "\n",
       "        [[0.02040801, 0.02040819, 0.02040822, ..., 0.02040818,\n",
       "          0.02040801, 0.02040805],\n",
       "         [0.02040822, 0.02040814, 0.02040807, ..., 0.02040818,\n",
       "          0.02040817, 0.02040823],\n",
       "         [0.02040811, 0.02040832, 0.02040824, ..., 0.02040854,\n",
       "          0.02040833, 0.02040857],\n",
       "         ...,\n",
       "         [0.02040826, 0.02040818, 0.02040813, ..., 0.02040826,\n",
       "          0.02040803, 0.02040796],\n",
       "         [0.02040827, 0.02040824, 0.02040828, ..., 0.02040816,\n",
       "          0.0204082 , 0.02040822],\n",
       "         [0.02040844, 0.02040823, 0.02040835, ..., 0.02040848,\n",
       "          0.0204084 , 0.02040834]]],\n",
       "\n",
       "\n",
       "       [[[0.02040827, 0.02040793, 0.02040812, ..., 0.02040792,\n",
       "          0.02040795, 0.0204079 ],\n",
       "         [0.02040817, 0.02040809, 0.02040793, ..., 0.02040827,\n",
       "          0.02040808, 0.02040822],\n",
       "         [0.02040821, 0.0204084 , 0.02040835, ..., 0.02040835,\n",
       "          0.02040834, 0.02040834],\n",
       "         ...,\n",
       "         [0.02040839, 0.02040816, 0.02040837, ..., 0.02040835,\n",
       "          0.02040828, 0.02040827],\n",
       "         [0.02040838, 0.02040819, 0.02040847, ..., 0.02040846,\n",
       "          0.0204084 , 0.02040812],\n",
       "         [0.02040817, 0.02040837, 0.02040825, ..., 0.02040829,\n",
       "          0.02040817, 0.0204084 ]],\n",
       "\n",
       "        [[0.02040792, 0.02040815, 0.02040825, ..., 0.02040826,\n",
       "          0.0204083 , 0.02040811],\n",
       "         [0.0204084 , 0.02040821, 0.02040819, ..., 0.02040828,\n",
       "          0.0204083 , 0.0204083 ],\n",
       "         [0.02040786, 0.0204079 , 0.02040776, ..., 0.02040786,\n",
       "          0.02040783, 0.02040785],\n",
       "         ...,\n",
       "         [0.0204083 , 0.02040805, 0.02040836, ..., 0.02040832,\n",
       "          0.02040811, 0.02040815],\n",
       "         [0.02040798, 0.02040812, 0.02040837, ..., 0.02040802,\n",
       "          0.02040817, 0.02040831],\n",
       "         [0.02040819, 0.02040815, 0.02040796, ..., 0.02040799,\n",
       "          0.02040798, 0.02040835]],\n",
       "\n",
       "        [[0.02040781, 0.02040832, 0.02040816, ..., 0.02040861,\n",
       "          0.02040838, 0.02040845],\n",
       "         [0.0204081 , 0.02040831, 0.02040839, ..., 0.02040837,\n",
       "          0.02040814, 0.02040817],\n",
       "         [0.02040806, 0.02040796, 0.02040808, ..., 0.02040812,\n",
       "          0.02040807, 0.02040821],\n",
       "         ...,\n",
       "         [0.02040811, 0.02040837, 0.02040843, ..., 0.02040808,\n",
       "          0.02040826, 0.02040816],\n",
       "         [0.02040821, 0.02040804, 0.02040832, ..., 0.02040794,\n",
       "          0.02040815, 0.02040824],\n",
       "         [0.02040818, 0.02040813, 0.02040836, ..., 0.02040851,\n",
       "          0.02040822, 0.02040833]],\n",
       "\n",
       "        [[0.02040801, 0.02040819, 0.02040822, ..., 0.02040815,\n",
       "          0.02040801, 0.02040805],\n",
       "         [0.02040819, 0.02040811, 0.02040804, ..., 0.02040814,\n",
       "          0.02040814, 0.02040819],\n",
       "         [0.0204081 , 0.0204083 , 0.02040823, ..., 0.02040848,\n",
       "          0.02040832, 0.02040856],\n",
       "         ...,\n",
       "         [0.02040831, 0.0204083 , 0.02040827, ..., 0.02040832,\n",
       "          0.0204083 , 0.02040815],\n",
       "         [0.02040827, 0.02040824, 0.02040828, ..., 0.02040821,\n",
       "          0.0204082 , 0.02040822],\n",
       "         [0.02040841, 0.0204082 , 0.02040832, ..., 0.02040836,\n",
       "          0.02040837, 0.02040831]]]], dtype=float32)>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_layer.attn_score ## batch_size, #atten_head, #num_patches(tokens), #num_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,d_model,dff,dropout_rate,num_heads,num_layers):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.patch_emb=PatchEmbedding(d_model)\n",
    "        self.enc_layers=[Encoder_Layer(d_model,dff,dropout_rate,num_heads)\n",
    "                        for _ in range(num_layers)]\n",
    "        \n",
    "        self.out_layer=tf.keras.layers.Dense(10,activation='softmax')\n",
    "        self.num_layers=num_layers\n",
    "        self.last_attn_score=None\n",
    "        \n",
    "    def call(self,images):\n",
    "        \n",
    "        ##getting patche_embedding the input image and adding positional information to it \n",
    "        x=self.patch_emb(images)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x=self.enc_layers[i](x)\n",
    "        \n",
    "        x=x[:,0,:] ## Global Information contained in class tokens\n",
    "        output_layer=self.out_layer(x)\n",
    "        self.last_attn_score=self.enc_layers[num_layers-1].attn_score\n",
    "        \n",
    "        return output_layer\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "##try it \n",
    "\n",
    "out_prob=Encoder(d_model,dff,dropout_rate,num_heads,2)(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 50, 256), dtype=float32, numpy=\n",
       "array([[[-0.01623954,  0.00486127,  0.0164399 , ...,  0.04257703,\n",
       "         -0.04099489, -0.00479007],\n",
       "        [ 0.03363803,  0.02882308,  0.00097749, ...,  0.04461608,\n",
       "         -0.00356733,  0.02496916],\n",
       "        [ 0.0081326 ,  0.02239582,  0.02580218, ..., -0.0143916 ,\n",
       "          0.01858768,  0.00436063],\n",
       "        ...,\n",
       "        [ 0.01920554,  0.04221523,  0.03295524, ..., -0.01009163,\n",
       "          0.00805972, -0.04000036],\n",
       "        [ 0.01623274,  0.00140528, -0.01379513, ..., -0.02688841,\n",
       "         -0.02851257,  0.01571264],\n",
       "        [ 0.04778477, -0.02345827,  0.02578367, ...,  0.01427089,\n",
       "          0.01456909, -0.02307239]],\n",
       "\n",
       "       [[-0.01623954,  0.00486127,  0.0164399 , ...,  0.04257703,\n",
       "         -0.04099489, -0.00479007],\n",
       "        [ 0.03363803,  0.02882308,  0.00097749, ...,  0.04461608,\n",
       "         -0.00356733,  0.02496916],\n",
       "        [ 0.0081326 ,  0.02239582,  0.02580218, ..., -0.0143916 ,\n",
       "          0.01858768,  0.00436063],\n",
       "        ...,\n",
       "        [ 0.01920554,  0.04221523,  0.03295524, ..., -0.01009163,\n",
       "          0.00805972, -0.04000036],\n",
       "        [ 0.01623274,  0.00140528, -0.01379513, ..., -0.02688841,\n",
       "         -0.02851257,  0.01571264],\n",
       "        [ 0.04778477, -0.02345827,  0.02578367, ...,  0.01427089,\n",
       "          0.01456909, -0.02307239]],\n",
       "\n",
       "       [[-0.01623954,  0.00486127,  0.0164399 , ...,  0.04257703,\n",
       "         -0.04099489, -0.00479007],\n",
       "        [ 0.03363803,  0.02882308,  0.00097749, ...,  0.04461608,\n",
       "         -0.00356733,  0.02496916],\n",
       "        [ 0.0081326 ,  0.02239582,  0.02580218, ..., -0.0143916 ,\n",
       "          0.01858768,  0.00436063],\n",
       "        ...,\n",
       "        [ 0.01920554,  0.04221523,  0.03295524, ..., -0.01009163,\n",
       "          0.00805972, -0.04000036],\n",
       "        [ 0.01623274,  0.00140528, -0.01379513, ..., -0.02688841,\n",
       "         -0.02851257,  0.01571264],\n",
       "        [ 0.04778477, -0.02345827,  0.02578367, ...,  0.01427089,\n",
       "          0.01456909, -0.02307239]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.01623954,  0.00486127,  0.0164399 , ...,  0.04257703,\n",
       "         -0.04099489, -0.00479007],\n",
       "        [ 0.03363803,  0.02882308,  0.00097749, ...,  0.04461608,\n",
       "         -0.00356733,  0.02496916],\n",
       "        [ 0.0081326 ,  0.02239582,  0.02580218, ..., -0.0143916 ,\n",
       "          0.01858768,  0.00436063],\n",
       "        ...,\n",
       "        [ 0.01920554,  0.04221523,  0.03295524, ..., -0.01009163,\n",
       "          0.00805972, -0.04000036],\n",
       "        [ 0.01623274,  0.00140528, -0.01379513, ..., -0.02688841,\n",
       "         -0.02851257,  0.01571264],\n",
       "        [ 0.04778477, -0.02345827,  0.02578367, ...,  0.01427089,\n",
       "          0.01456909, -0.02307239]],\n",
       "\n",
       "       [[-0.01623954,  0.00486127,  0.0164399 , ...,  0.04257703,\n",
       "         -0.04099489, -0.00479007],\n",
       "        [ 0.03363803,  0.02882308,  0.00097749, ...,  0.04461608,\n",
       "         -0.00356733,  0.02496916],\n",
       "        [ 0.0081326 ,  0.02239582,  0.02580218, ..., -0.0143916 ,\n",
       "          0.01858768,  0.00436063],\n",
       "        ...,\n",
       "        [ 0.01920554,  0.04221523,  0.03295524, ..., -0.01009163,\n",
       "          0.00805972, -0.04000036],\n",
       "        [ 0.01623274,  0.00140528, -0.01379513, ..., -0.02688841,\n",
       "         -0.02851257,  0.01571264],\n",
       "        [ 0.04778477, -0.02345827,  0.02578367, ...,  0.01427089,\n",
       "          0.01456909, -0.02307239]],\n",
       "\n",
       "       [[-0.01623954,  0.00486127,  0.0164399 , ...,  0.04257703,\n",
       "         -0.04099489, -0.00479007],\n",
       "        [ 0.03363803,  0.02882308,  0.00097749, ...,  0.04461608,\n",
       "         -0.00356733,  0.02496916],\n",
       "        [ 0.0081326 ,  0.02239582,  0.02580218, ..., -0.0143916 ,\n",
       "          0.01858768,  0.00436063],\n",
       "        ...,\n",
       "        [ 0.12874775,  0.15321681,  0.0625845 , ...,  0.05690698,\n",
       "         -0.11858325,  0.02929731],\n",
       "        [ 0.01623274,  0.00140528, -0.01379513, ..., -0.02688841,\n",
       "         -0.02851257,  0.01571264],\n",
       "        [ 0.04778477, -0.02345827,  0.02578367, ...,  0.01427089,\n",
       "          0.01456909, -0.02307239]]], dtype=float32)>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PatchEmbedding(d_model)(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is working, it is time to train. Since, it is simple MNIST task we will not use Optimizer wtih weight_decay. \n",
    "We will use Adam, as this task itself is very simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_parameters\n",
    "num_heads=4\n",
    "d_model=256\n",
    "dff=d_model*3\n",
    "dropout_rate=0.3\n",
    "num_layers=2\n",
    "\n",
    "model=Encoder(d_model,dff,dropout_rate,num_heads,num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "937/937 [==============================] - 28s 27ms/step - loss: 0.8316 - accuracy: 0.7179\n",
      "Epoch 2/4\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.2761 - accuracy: 0.9136\n",
      "Epoch 3/4\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.2124 - accuracy: 0.9336\n",
      "Epoch 4/4\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.1783 - accuracy: 0.9439\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset,epochs=4,verbose=True) \n",
    "\"You can train more to get better result, the aim of this turtorial is just showing how we can buld ViT from scratch\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 2s 12ms/step - loss: 0.1260 - accuracy: 0.9622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12604284286499023, 0.9622395634651184]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing the accuracy on Test Dataset\n",
    "model.evaluate(test_dataset,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as patch_39_layer_call_fn, patch_39_layer_call_and_return_conditional_losses, dense_151_layer_call_fn, dense_151_layer_call_and_return_conditional_losses, embedding_31_layer_call_fn while saving (showing 5 of 50). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "## Saving the model\n",
    "model_checkpoint='./saved_model'\n",
    "model.save(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how to plot the attention heatmap\n",
    "\n",
    "## Frist step lets get a image from test_dataset\n",
    "\n",
    "for test_images,_ in test_dataset.take(1):\n",
    "    random_idx=tf.random.uniform(\n",
    "    shape=(1,),\n",
    "    minval=0,\n",
    "    maxval=64,\n",
    "    dtype=tf.dtypes.int32,\n",
    "  ).numpy()[0]\n",
    "    test_image=tf.expand_dims(test_images[random_idx],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 28, 28, 1])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x282db28fa00>"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plotting the images\n",
    "\n",
    "plt.imshow(test_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model prediction \n",
    "\n",
    "prediction=tf.argmax(model(test_image),axis=1)\n",
    "attn_score=model.last_attn_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([7], dtype=int64)>"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 50, 50), dtype=float32, numpy=\n",
       "array([[[1.08839641e-03, 4.68478975e-05, 1.04467064e-04, ...,\n",
       "         1.25285427e-04, 4.46273079e-05, 5.92565448e-05],\n",
       "        [9.33375151e-04, 1.33031441e-04, 2.16387154e-04, ...,\n",
       "         2.31911414e-04, 1.52377805e-04, 1.71031890e-04],\n",
       "        [2.84217705e-04, 2.09956197e-05, 4.03287595e-05, ...,\n",
       "         5.11030885e-05, 2.41381713e-05, 2.91913420e-05],\n",
       "        ...,\n",
       "        [5.71099627e-05, 1.67823680e-06, 4.07186008e-06, ...,\n",
       "         5.56009854e-06, 1.86413399e-06, 2.48219430e-06],\n",
       "        [6.74880750e-04, 6.05270798e-05, 1.08697284e-04, ...,\n",
       "         1.29355409e-04, 6.83804392e-05, 7.95298693e-05],\n",
       "        [9.37778212e-04, 1.26959800e-04, 2.05660093e-04, ...,\n",
       "         2.57291453e-04, 1.48325911e-04, 1.68035214e-04]],\n",
       "\n",
       "       [[1.29234031e-01, 1.23195513e-03, 2.28641997e-03, ...,\n",
       "         8.53242073e-03, 1.20669161e-03, 1.07901124e-03],\n",
       "        [3.10436606e-01, 1.57976360e-03, 2.14051129e-03, ...,\n",
       "         5.47097577e-03, 1.52057153e-03, 1.12153927e-03],\n",
       "        [3.21165979e-01, 1.06080028e-03, 1.55140285e-03, ...,\n",
       "         4.34081117e-03, 1.01632695e-03, 7.24895275e-04],\n",
       "        ...,\n",
       "        [4.31469172e-01, 3.24338122e-04, 5.58973930e-04, ...,\n",
       "         2.49550911e-03, 3.55469121e-04, 2.26930119e-04],\n",
       "        [3.58525664e-01, 8.50310316e-04, 1.27010047e-03, ...,\n",
       "         3.97394830e-03, 8.31053476e-04, 6.05428242e-04],\n",
       "        [3.04167658e-01, 1.52458844e-03, 2.07272032e-03, ...,\n",
       "         5.27650537e-03, 1.46209530e-03, 1.06943783e-03]],\n",
       "\n",
       "       [[1.29890011e-03, 1.49650477e-05, 3.37413694e-05, ...,\n",
       "         5.65123046e-05, 1.37059706e-05, 2.03488726e-05],\n",
       "        [9.18023847e-03, 2.30496182e-04, 4.52273263e-04, ...,\n",
       "         7.51991989e-04, 2.19722555e-04, 3.15176556e-04],\n",
       "        [3.90745793e-03, 7.59594259e-05, 1.56705180e-04, ...,\n",
       "         2.61380745e-04, 6.65847037e-05, 1.02986683e-04],\n",
       "        ...,\n",
       "        [5.22361661e-04, 2.35692710e-06, 6.73085879e-06, ...,\n",
       "         1.02972463e-05, 2.08580900e-06, 3.47685045e-06],\n",
       "        [4.94394870e-03, 9.01931780e-05, 1.83416458e-04, ...,\n",
       "         3.17852478e-04, 8.47298579e-05, 1.24767015e-04],\n",
       "        [7.33420998e-03, 2.00938550e-04, 3.84165847e-04, ...,\n",
       "         6.45019114e-04, 1.84592878e-04, 2.74279970e-04]],\n",
       "\n",
       "       [[6.12847786e-03, 2.21733630e-04, 5.32355916e-04, ...,\n",
       "         1.12652685e-03, 2.05305900e-04, 2.21260678e-04],\n",
       "        [1.09396197e-01, 1.57915277e-03, 2.68105953e-03, ...,\n",
       "         8.55049957e-03, 2.29068939e-03, 1.82698853e-03],\n",
       "        [1.03760280e-01, 1.29726774e-03, 2.24822131e-03, ...,\n",
       "         6.82462240e-03, 1.76833011e-03, 1.48206472e-03],\n",
       "        ...,\n",
       "        [4.02128547e-02, 1.18989585e-04, 2.85605231e-04, ...,\n",
       "         1.33080594e-03, 1.54865076e-04, 1.33746711e-04],\n",
       "        [5.74896075e-02, 4.92913881e-04, 9.97096882e-04, ...,\n",
       "         3.57274781e-03, 6.56358781e-04, 5.44505718e-04],\n",
       "        [8.56506452e-02, 1.29178597e-03, 2.25539343e-03, ...,\n",
       "         6.71452610e-03, 1.78419880e-03, 1.47713965e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_attention_on_image(image, attention_maps,num_heads):\n",
    "    ncols=num_heads//2\n",
    "    nrows=num_heads//2\n",
    "    fig,axes=plt.subplots(ncols=ncols,nrows=nrows)\n",
    "\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            head=i+j\n",
    "            \n",
    "    # Normalize the attention map\n",
    "            attention_map=attention_maps[head].numpy()\n",
    "            attention_map = (attention_map - np.min(attention_map)) / (np.max(attention_map) - np.min(attention_map))\n",
    "\n",
    "            # Resize attention_map to image size using bilinear interpolation\n",
    "            attention_map_resized = cv2.resize(attention_map, (image.shape[1], image.shape[0]))\n",
    "            attention_map_resized=cv2.cvtColor(attention_map_resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            axes[i][j].imshow(image, cmap='gray')  # grayscale image\n",
    "            axes[i][j].imshow(attention_map_resized, cmap='jet', alpha=0.5)  # Overlaying the attention map with transparency\n",
    "\n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "overlay_attention_on_image(test_image[0],attn_score,num_heads=num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
