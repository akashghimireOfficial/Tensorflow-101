{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this turorial we we train a simple CNN model on MNIST dataset. However, in this training we will not use predefined methods such as model.compile() and model.fit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x,y):\n",
    "    print('x.shape ',x.shape)\n",
    "    x=tf.cast(x,dtype=tf.float32)/255.0\n",
    "    x=tf.reshape(x,shape=(28,28,1))\n",
    "    y=tf.one_hot(y,depth=10) ## \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape  (28, 28)\n",
      "x.shape  (28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_ds=tf.data.Dataset.from_tensor_slices((x_train,y_train)).map(preprocess).cache().batch(256).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds=tf.data.Dataset.from_tensor_slices((x_test,y_test)).map(preprocess).cache().batch(256).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 28, 28, 1)\n",
      "(256, 10)\n"
     ]
    }
   ],
   "source": [
    "for img,label in train_ds.take(1):\n",
    "    print(img.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tf.keras.Input(shape=(28,28,1))\n",
    "x=Conv2D(64,3,activation='relu')(inputs)\n",
    "x=Conv2D(128,3,activation='relu')(x)\n",
    "x=Flatten()(x)\n",
    "outputs=Dense(10,activation='softmax')(x)\n",
    "model=tf.keras.Model(inputs,outputs,name='CNN_MODEL')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Loss function, Optimizer and accuracy functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fnc=tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "acc_fnc=tf.keras.metrics.categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc(true_label,pred_label):\n",
    "    true=tf.argmax(true_label,axis=1)\n",
    "    pred=tf.argmax(pred_label,axis=1)\n",
    "    acc=tf.reduce_sum(tf.cast(tf.equal(true,pred),tf.float32))/tf.cast(true.shape[0],tf.float32)\n",
    "    \"\"\"\n",
    "    Above three lines is same as using: tf.reduce_mean(tf.keras.metrics.categorical_accuracy(true_label,pred_label)).\n",
    "    In this way we can define our other loss.\n",
    "    \"\"\"\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Batch Num : 0\tLoss Value: 2.307\t Accuracy: 0.109\n",
      "Epoch : 0\n",
      "Batch Num : 100\tLoss Value: 0.128\t Accuracy: 0.973\n",
      "Epoch : 0\n",
      "Batch Num : 200\tLoss Value: 0.084\t Accuracy: 0.980\n",
      "Epoch : 1\n",
      "Batch Num : 0\tLoss Value: 0.097\t Accuracy: 0.973\n",
      "Epoch : 1\n",
      "Batch Num : 100\tLoss Value: 0.069\t Accuracy: 0.988\n",
      "Epoch : 1\n",
      "Batch Num : 200\tLoss Value: 0.063\t Accuracy: 0.984\n",
      "Epoch : 2\n",
      "Batch Num : 0\tLoss Value: 0.078\t Accuracy: 0.977\n",
      "Epoch : 2\n",
      "Batch Num : 100\tLoss Value: 0.048\t Accuracy: 0.980\n",
      "Epoch : 2\n",
      "Batch Num : 200\tLoss Value: 0.059\t Accuracy: 0.980\n",
      "Epoch : 3\n",
      "Batch Num : 0\tLoss Value: 0.058\t Accuracy: 0.984\n",
      "Epoch : 3\n",
      "Batch Num : 100\tLoss Value: 0.022\t Accuracy: 0.988\n",
      "Epoch : 3\n",
      "Batch Num : 200\tLoss Value: 0.043\t Accuracy: 0.988\n",
      "Epoch : 4\n",
      "Batch Num : 0\tLoss Value: 0.037\t Accuracy: 0.984\n",
      "Epoch : 4\n",
      "Batch Num : 100\tLoss Value: 0.020\t Accuracy: 0.996\n",
      "Epoch : 4\n",
      "Batch Num : 200\tLoss Value: 0.044\t Accuracy: 0.996\n",
      "Total training time: 0.029\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch_num in range(epochs):\n",
    "\n",
    "    for batch_num,(img,true_label) in enumerate(train_ds):\n",
    "\n",
    "        start_time=time.time()\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            pred_label=model(img)\n",
    "            \n",
    "            loss=loss_fnc(true_label,pred_label)\n",
    "\n",
    "\n",
    "        grad=tape.gradient(loss,model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grad,model.trainable_weights)) # learn about in which condition we use update state. \n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "        acc=custom_acc(true_label,pred_label)\n",
    "        \n",
    "\n",
    "        if batch_num %100==0:\n",
    "            print('Epoch :',epoch_num)\n",
    "            print('Batch Num : {}\\tLoss Value: {:.3f}\\t Accuracy: {:.3f}'.format(batch_num,loss,acc))\n",
    "    \n",
    "total_training_time=time.time()-start_time\n",
    "\n",
    "print('Total training time: {:.3f}'.format(total_training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 9ms/step\n",
      "8/8 [==============================] - 0s 10ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Average Accuracy: 0.983\n"
     ]
    }
   ],
   "source": [
    "## Evaluating the loss \n",
    "accs=[]\n",
    "\n",
    "for img,label in test_ds:\n",
    "    pred=model.predict(img)\n",
    "    acc=custom_acc(label,pred)\n",
    "    accs.append(acc)\n",
    "\n",
    "print('Average Accuracy: {:.3f}'.format(tf.reduce_mean(accs)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above training loop is training eagerly, which is slower. We can use tf.function to speed up the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs,label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_label=model(inputs)\n",
    "        \n",
    "        loss=loss_fnc(label,pred_label)\n",
    "\n",
    "    grad=tape.gradient(loss,model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grad,model.trainable_weights))\n",
    "\n",
    "    acc=custom_acc(pred_label=pred_label,true_label=label)\n",
    "\n",
    "    return acc,loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Batch Num : 0\tLoss Value: 0.020\t Accuracy: 0.992\n",
      "Epoch : 0\n",
      "Batch Num : 100\tLoss Value: 0.008\t Accuracy: 1.000\n",
      "Epoch : 0\n",
      "Batch Num : 200\tLoss Value: 0.035\t Accuracy: 0.996\n",
      "Epoch : 1\n",
      "Batch Num : 0\tLoss Value: 0.021\t Accuracy: 0.996\n",
      "Epoch : 1\n",
      "Batch Num : 100\tLoss Value: 0.008\t Accuracy: 0.996\n",
      "Epoch : 1\n",
      "Batch Num : 200\tLoss Value: 0.024\t Accuracy: 0.988\n",
      "Epoch : 2\n",
      "Batch Num : 0\tLoss Value: 0.010\t Accuracy: 0.996\n",
      "Epoch : 2\n",
      "Batch Num : 100\tLoss Value: 0.026\t Accuracy: 0.992\n",
      "Epoch : 2\n",
      "Batch Num : 200\tLoss Value: 0.012\t Accuracy: 0.996\n",
      "Epoch : 3\n",
      "Batch Num : 0\tLoss Value: 0.011\t Accuracy: 0.992\n",
      "Epoch : 3\n",
      "Batch Num : 100\tLoss Value: 0.006\t Accuracy: 1.000\n",
      "Epoch : 3\n",
      "Batch Num : 200\tLoss Value: 0.013\t Accuracy: 0.992\n",
      "Epoch : 4\n",
      "Batch Num : 0\tLoss Value: 0.007\t Accuracy: 0.996\n",
      "Epoch : 4\n",
      "Batch Num : 100\tLoss Value: 0.014\t Accuracy: 0.996\n",
      "Epoch : 4\n",
      "Batch Num : 200\tLoss Value: 0.011\t Accuracy: 0.996\n",
      "Total training time: 0.029\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch_num in range(epochs):\n",
    "\n",
    "    for batch_num,(img,true_label) in enumerate(train_ds):\n",
    "\n",
    "        start_time=time.time()\n",
    "\n",
    "        acc,loss=train_step(img,true_label)\n",
    "        \n",
    "\n",
    "        if batch_num %100==0:\n",
    "            print('Epoch :',epoch_num)\n",
    "            print('Batch Num : {}\\tLoss Value: {:.3f}\\t Accuracy: {:.3f}'.format(batch_num,loss,acc))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be obseved that using tf.function() training time reduce by 10 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
