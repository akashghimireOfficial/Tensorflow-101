{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to modules, layers, and models\n",
    "> In this turtorial we will be learning how to build some simple tensorflow modules. <br> We will also learn to build model using keras api."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build tensorflow model we will be using ***tf.Module*** class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 09:57:03.166576: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-10 09:57:03.327860: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-10 09:57:03.382029: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-10 09:57:03.935133: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/usr/local/cuda-11.6/lib\n",
      "2022-10-10 09:57:03.935202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/usr/local/cuda-11.6/lib\n",
      "2022-10-10 09:57:03.935207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os \n",
    "from datetime import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 09:57:06.588958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-10 09:57:06.627291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-10 09:57:06.627708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4120)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### defining a Dense layer using tf.Module\n",
    "\n",
    "\n",
    "class Dense(tf.Module):\n",
    "    def __init__(self,in_features,out_features,name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.w=tf.Variable(tf.random.normal([in_features,out_features]),name='w') ## shape==in_features,out_features\n",
    "        self.b=tf.Variable(tf.zeros([out_features],name='b'))\n",
    "\n",
    "    def __call__(self,x):\n",
    "        y=tf.matmul(x,self.w)+self.b\n",
    "        return tf.nn.relu(y)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Dense(in_features=3,out_features=2,name='dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.constant([[1,2,3]],dtype=tf.float32)\n",
    "model=Dense(3,2,'dense')\n",
    "output=model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output : [[0.        6.8176084]]\n"
     ]
    }
   ],
   "source": [
    "print('model output : {}'.format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.shape: (1, 3)\n",
      "output.shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print('input.shape: {}\\noutput.shape: {}'.format(x.shape,output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=\n",
       " array([[-0.5247791 ,  0.10138043],\n",
       "        [-0.8302663 ,  0.953391  ],\n",
       "        [ 0.60742116,  1.6031486 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Seeing the trainables parameter of models\n",
    "model.trainable_variables ## which is are bias and weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating Dense which can be build only from out_features\n",
    "\n",
    "class FlexibleDense(tf.Module):\n",
    "    def __init__(self,out_features,name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.out_features=out_features\n",
    "        self.is_built=False\n",
    "    def __call__(self,x):\n",
    "        self.in_features=x.shape[-1]\n",
    "        if not self.is_built:\n",
    "            self.w=tf.Variable(tf.random.normal([self.in_features,self.out_features]),name='w')\n",
    "            self.b=tf.Variable(tf.zeros([self.out_features]),name='b')\n",
    "            self.is_built=True\n",
    "        y=tf.matmul(x,self.w)+self.b\n",
    "        return tf.nn.relu(y)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model=FlexibleDense(out_features=2)\n",
    "output_f=f_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.      , 3.180626]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving weights using ***checkpoints***\n",
    "> You can save a tf.Module as both a ***checkpoint*** and a ***SavedModel*** <br>\n",
    ">  Checkpoints are just the weights (that is, the values of the set of variables inside the module and its submodules). <br>\n",
    "> Checkpoints consist of two kinds of files: the data itself and an index file for metadata. The index file keeps track of what is actually saved and the numbering of checkpoints, while the checkpoint data contains the variable values and their attribute lookup paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint/my_checkpoint'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Saving a model as checkpoint \n",
    "chkp_path='checkpoint/my_checkpoint'\n",
    "checkpoint=tf.train.Checkpoint(model=model)\n",
    "checkpoint.write(chkp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_checkpoint.data-00000-of-00001  my_checkpoint.index\n"
     ]
    }
   ],
   "source": [
    "## Seeing what is inside of checkpoint\n",
    "!ls checkpoint*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look inside a checkpoint to be sure the whole collection of variables is saved, sorted by the Python object that contains them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_CHECKPOINTABLE_OBJECT_GRAPH', []),\n",
       " ('model/b/.ATTRIBUTES/VARIABLE_VALUE', [2]),\n",
       " ('model/w/.ATTRIBUTES/VARIABLE_VALUE', [3, 2])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.list_variables(chkp_path) ## Shows what variables are saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbf281ae4d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loading the weight to new model using checkpoints \n",
    "new_model=Dense(in_features=3,out_features=2,name='new_dense')\n",
    "new_checkpoint=tf.train.Checkpoint(model=new_model)\n",
    "new_checkpoint.restore(\"checkpoint/my_checkpoint\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_model output : [[0.        6.8176084]]\n"
     ]
    }
   ],
   "source": [
    "## Feeding the same value x to new model\n",
    "new_output=new_model(x)\n",
    "print('new_model output : {}'.format(new_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=bool, numpy=array([[ True,  True]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## As the trainables weights value were restored the output from two models are same\n",
    "new_output==output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving functions\n",
    "TensorFlow can run models without the original Python objects, as demonstrated by TensorFlow Serving and TensorFlow Lite, even when you download a trained model from TensorFlow Hub.\n",
    "\n",
    "TensorFlow needs to know how to do the computations described in Python, but without the original code. To do this, you can make a graph, which is described in the Introduction to graphs and functions guide.\n",
    "\n",
    "This graph contains operations, or ops, that implement the function.\n",
    "\n",
    "You can define a graph in the model above by adding the @tf.function decorator to indicate that this code should run as a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequentialModule(tf.Module):\n",
    "  def __init__(self, name=None):\n",
    "    super().__init__(name=name)\n",
    "\n",
    "    self.dense_1 = Dense(in_features=3, out_features=3)\n",
    "    self.dense_2 = Dense(in_features=3, out_features=2)\n",
    "\n",
    "  @tf.function ## Graph execution\n",
    "  def __call__(self, x):\n",
    "    x = self.dense_1(x)\n",
    "    return self.dense_2(x)\n",
    "\n",
    "# You have made a model with a graph!\n",
    "my_model = MySequentialModule(name=\"the_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-07 11:02:52.901419: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-10-07 11:02:52.901446: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-10-07 11:02:52.901641: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1630] Profiler found 1 GPUs\n",
      "2022-10-07 11:02:52.901933: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/usr/local/cuda-11.6/lib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[12.442682  2.187654]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Set up logging.\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = \"logs/func/%s\" % stamp\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Create a new model to get a fresh trace\n",
    "# Otherwise the summary will not see the graph.\n",
    "new_model = MySequentialModule()\n",
    "\n",
    "# Bracket the function call with\n",
    "# tf.summary.trace_on() and tf.summary.trace_export().\n",
    "tf.summary.trace_on(graph=True)\n",
    "tf.profiler.experimental.start(logdir)\n",
    "# Call only one tf.function when tracing.\n",
    "z = print(new_model(tf.constant([[2.0, 2.0, 2.0]])))\n",
    "with writer.as_default():\n",
    "  tf.summary.trace_export(\n",
    "      name=\"my_func_trace\",\n",
    "      step=0,\n",
    "      profiler_outdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 111689), started 0:05:08 ago. (Use '!kill 111689' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-abe207dd7555d90e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-abe207dd7555d90e\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #docs_infra: no_execute\n",
    "# %tensorboard --logdir logs/func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving weights as ***SavedModel***\n",
    "> this is the recommended way of sharing completely trained models. Unlike checkpoints it contains both collection of fucntion as well as collection of weights.\n",
    "> <br> tf.saved_model.save(my_model,'model_path')\n",
    "> <br> The saved_model.pb file is a protocol buffer describing the functional tf.Graph.\n",
    "> <br> Models and layers can be loaded from this representation without actually making an instance of the class that created it. This is desired in situations where you do not have (or want) a Python interpreter, such as serving at scale or on an edge device, or in situations where the original Python code is not available or practical to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "## Saving the model\n",
    "tf.saved_model.save(model,'saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['variables', 'assets', 'saved_model.pb']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## what is inside of saved_model\n",
    "os.listdir('saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['variables.data-00000-of-00001', 'variables.index']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what are inside of saved_model/variables\n",
    "os.listdir('saved_model/variables/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a tf.keras Model\n",
    ">***tf.keras.layers.Layer*** is the base class of all Keras layers, and it inherits from ***tf.Module***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a simple tf.keras Dense\n",
    "\n",
    "class kerasDense(tf.keras.layers.Layer):\n",
    "    def __init__(self,in_features,out_features,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.w=tf.Variable(tf.random.normal([in_features,out_features]),name='w')\n",
    "        self.b=tf.Variable(tf.zeros([out_features]),name='b')\n",
    "\n",
    "    def call(self,x):\n",
    "        y=tf.matmul(x,self.w)+self.b\n",
    "        return tf.nn.relu(y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.constant([[1,2,3]],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[9.436285  0.        0.        3.8666575 0.       ]], shape=(1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "output=kerasDense(3,5)\n",
    "print(output(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a flexible models\n",
    "\n",
    "**The build step**\n",
    "As noted, it's convenient in many cases to wait to create variables until you are sure of the input shape.\n",
    "Keras layers come with an extra lifecycle step that allows you more flexibility in how you define your layers. This is defined in the build function.\n",
    "build is called exactly once, and it is called with the shape of the input. It's usually used to create variables (weights).\n",
    "\n",
    "> You can rewrite MyDense layer above to be flexible to the size of its inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexiblekerasDense(tf.keras.layers.Layer):\n",
    "    def __init__(self,out_features,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.out_features=out_features\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w=tf.Variable(tf.random.normal([input_shape[-1],self.out_features]),name='w')\n",
    "        self.b=tf.Variable(tf.zeros([self.out_features]),name='b') \n",
    "    \n",
    "    def call(self,x):\n",
    "        y=tf.matmul(x,self.w)+self.b\n",
    "        return tf.nn.relu(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<property at 0x7f10add0fc40>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FlexiblekerasDense.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "densekeras=FlexiblekerasDense(out_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densekeras.trainable_variables ## Variables are only build after getting the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output from flexible keras dense modle : [[1.5492523 5.7922688 8.022979  2.0196662 1.9079834]]\n"
     ]
    }
   ],
   "source": [
    "print('output from flexible keras dense modle : {}'.format(densekeras(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the keras model\n",
    "\n",
    "While keras model can also be saved with tf.saved_model; it is advisable to save the model with model.save('path')\n",
    "> model.save provides some additional keras methods which are not provided by tf.saved_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining Keras model\n",
    "input=tf.keras.Input([3,])\n",
    "x=FlexiblekerasDense(out_features=5)(input)\n",
    "model=tf.keras.Model(input,x,name='simple_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3)]               0         \n",
      "                                                                 \n",
      " flexiblekeras_dense_3 (Flex  (None, 5)                20        \n",
      " iblekerasDense)                                                 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: keras_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c93af7433719cf61beb232a937287b5f6ac44c5a03632b389ba7312dbdbeed85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
