{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to modules, layers, and models\n",
    "> In this turtorial we will be learning how to build some simple tensorflow modules. <br> We will also learn to build model using keras api."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build tensorflow model we will be using ***tf.Module*** class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os \n",
    "from datetime import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4120)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### defining a Dense layer using tf.Module\n",
    "\n",
    "\n",
    "class Dense(tf.Module):\n",
    "    def __init__(self,in_features,out_features,name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.w=tf.Variable(tf.random.normal([in_features,out_features]),name='w') ## shape==in_features,out_features\n",
    "        self.b=tf.Variable(tf.zeros([out_features],name='b'))\n",
    "\n",
    "    def __call__(self,x):\n",
    "        y=tf.matmul(x,self.w)+self.b\n",
    "        return tf.nn.relu(y)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Dense(in_features=3,out_features=2,name='dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.constant([[1,2,3]],dtype=tf.float32)\n",
    "model=Dense(3,2,'dense')\n",
    "output=model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output : [[0.        6.8176084]]\n"
     ]
    }
   ],
   "source": [
    "print('model output : {}'.format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.shape: (1, 3)\n",
      "output.shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print('input.shape: {}\\noutput.shape: {}'.format(x.shape,output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=\n",
       " array([[-0.5247791 ,  0.10138043],\n",
       "        [-0.8302663 ,  0.953391  ],\n",
       "        [ 0.60742116,  1.6031486 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Seeing the trainables parameter of models\n",
    "model.trainable_variables ## which is are bias and weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating Dense which can be build only from out_features\n",
    "\n",
    "class FlexibleDense(tf.Module):\n",
    "    def __init__(self,out_features,name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.out_features=out_features\n",
    "        self.is_built=False\n",
    "    def __call__(self,x):\n",
    "        self.in_features=x.shape[-1]\n",
    "        if not self.is_built:\n",
    "            self.w=tf.Variable(tf.random.normal([self.in_features,self.out_features]),name='w')\n",
    "            self.b=tf.Variable(tf.zeros([self.out_features]),name='b')\n",
    "            self.is_built=True\n",
    "        y=tf.matmul(x,self.w)+self.b\n",
    "        return tf.nn.relu(y)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model=FlexibleDense(out_features=2)\n",
    "output_f=f_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.      , 3.180626]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving weights using ***checkpoints***\n",
    "> You can save a tf.Module as both a ***checkpoint*** and a ***SavedModel*** <br>\n",
    ">  Checkpoints are just the weights (that is, the values of the set of variables inside the module and its submodules). <br>\n",
    "> Checkpoints consist of two kinds of files: the data itself and an index file for metadata. The index file keeps track of what is actually saved and the numbering of checkpoints, while the checkpoint data contains the variable values and their attribute lookup paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint/my_checkpoint'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Saving a model as checkpoint \n",
    "chkp_path='checkpoint/my_checkpoint'\n",
    "checkpoint=tf.train.Checkpoint(model=model)\n",
    "checkpoint.write(chkp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_checkpoint.data-00000-of-00001  my_checkpoint.index\n"
     ]
    }
   ],
   "source": [
    "## Seeing what is inside of checkpoint\n",
    "!ls checkpoint*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look inside a checkpoint to be sure the whole collection of variables is saved, sorted by the Python object that contains them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_CHECKPOINTABLE_OBJECT_GRAPH', []),\n",
       " ('model/b/.ATTRIBUTES/VARIABLE_VALUE', [2]),\n",
       " ('model/w/.ATTRIBUTES/VARIABLE_VALUE', [3, 2])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.list_variables(chkp_path) ## Shows what variables are saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbf281ae4d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loading the weight to new model using checkpoints \n",
    "new_model=Dense(in_features=3,out_features=2,name='new_dense')\n",
    "new_checkpoint=tf.train.Checkpoint(model=new_model)\n",
    "new_checkpoint.restore(\"checkpoint/my_checkpoint\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_model output : [[0.        6.8176084]]\n"
     ]
    }
   ],
   "source": [
    "## Feeding the same value x to new model\n",
    "new_output=new_model(x)\n",
    "print('new_model output : {}'.format(new_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=bool, numpy=array([[ True,  True]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## As the trainables weights value were restored the output from two models are same\n",
    "new_output==output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving functions\n",
    "TensorFlow can run models without the original Python objects, as demonstrated by TensorFlow Serving and TensorFlow Lite, even when you download a trained model from TensorFlow Hub.\n",
    "\n",
    "TensorFlow needs to know how to do the computations described in Python, but without the original code. To do this, you can make a graph, which is described in the Introduction to graphs and functions guide.\n",
    "\n",
    "This graph contains operations, or ops, that implement the function.\n",
    "\n",
    "You can define a graph in the model above by adding the @tf.function decorator to indicate that this code should run as a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequentialModule(tf.Module):\n",
    "  def __init__(self, name=None):\n",
    "    super().__init__(name=name)\n",
    "\n",
    "    self.dense_1 = Dense(in_features=3, out_features=3)\n",
    "    self.dense_2 = Dense(in_features=3, out_features=2)\n",
    "\n",
    "  @tf.function ## Graph execution\n",
    "  def __call__(self, x):\n",
    "    x = self.dense_1(x)\n",
    "    return self.dense_2(x)\n",
    "\n",
    "# You have made a model with a graph!\n",
    "my_model = MySequentialModule(name=\"the_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-07 11:02:52.901419: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-10-07 11:02:52.901446: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-10-07 11:02:52.901641: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1630] Profiler found 1 GPUs\n",
      "2022-10-07 11:02:52.901933: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/usr/local/cuda-11.6/lib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[12.442682  2.187654]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Set up logging.\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = \"logs/func/%s\" % stamp\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Create a new model to get a fresh trace\n",
    "# Otherwise the summary will not see the graph.\n",
    "new_model = MySequentialModule()\n",
    "\n",
    "# Bracket the function call with\n",
    "# tf.summary.trace_on() and tf.summary.trace_export().\n",
    "tf.summary.trace_on(graph=True)\n",
    "tf.profiler.experimental.start(logdir)\n",
    "# Call only one tf.function when tracing.\n",
    "z = print(new_model(tf.constant([[2.0, 2.0, 2.0]])))\n",
    "with writer.as_default():\n",
    "  tf.summary.trace_export(\n",
    "      name=\"my_func_trace\",\n",
    "      step=0,\n",
    "      profiler_outdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 111689), started 0:05:08 ago. (Use '!kill 111689' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-abe207dd7555d90e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-abe207dd7555d90e\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "%tensorboard --logdir logs/func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving weights as ***SavedModel***\n",
    "> this is the recommended way of sharing completely trained models. Unlike checkpoints it contains both collection of fucntion as well as collection of weights.\n",
    "> <br> tf.saved_model.save(my_model,'model_path')\n",
    "> <br> The saved_model.pb file is a protocol buffer describing the functional tf.Graph.\n",
    "> <br> Models and layers can be loaded from this representation without actually making an instance of the class that created it. This is desired in situations where you do not have (or want) a Python interpreter, such as serving at scale or on an edge device, or in situations where the original Python code is not available or practical to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "## Saving the model\n",
    "tf.saved_model.save(model,'saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['variables', 'assets', 'saved_model.pb']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## what is inside of saved_model\n",
    "os.listdir('saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['variables.data-00000-of-00001', 'variables.index']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what are inside of saved_model/variables\n",
    "os.listdir('saved_model/variables/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c93af7433719cf61beb232a937287b5f6ac44c5a03632b389ba7312dbdbeed85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
