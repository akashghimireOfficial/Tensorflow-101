{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "> Tensors are multi-dimensional arrays. <br> Tensors are immutable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 20:06:29.906285: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-01 20:06:29.978544: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-01 20:06:29.996737: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-01 20:06:30.379491: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/usr/local/cuda-11.6/lib\n",
      "2022-10-01 20:06:30.379529: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/usr/local/cuda-11.6/lib\n",
      "2022-10-01 20:06:30.379532: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(3) ## Disable printing information and warning\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Basic Tensors\n",
    ">\"scaler\"==\"rank-o\" tensor <br> \"vector\" == \"rank-1\" tensor <br>  \"matrix\"==\"rank-2\" tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 20:06:30.902733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:06:30.920678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:06:30.920803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:06:30.921693: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-01 20:06:30.922348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:06:30.922484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:06:30.922549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:06:31.275207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:06:31.275325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:06:31.275388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:06:31.275451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 650 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "## Creating rank_0 tensor\n",
    "rank_0_tensor=tf.constant(4) ## by default the dtype used is tf.int32\n",
    "print(rank_0_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 2. 3. 4.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Creating rank_1 Tensor\n",
    "rank_1_tensor=tf.constant([1,2,3,4],dtype=tf.float32) \n",
    "print(rank_1_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "## Creating rank 2 Tensor \n",
    "rank_2_tensor=tf.constant([[1,2],[3,4]])\n",
    "print(rank_2_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic math operation using tf.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.constant([[1,2],[3,4]],dtype=tf.float32)\n",
    "b=tf.ones([2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2. 3.]\n",
      " [4. 5.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tf.add(a,b)) ##addition\n",
    "print(tf.multiply(a,b)) ## element wise multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[[1.,2.,3.]]\n",
    "w=tf.constant([[1.,2.],[3.,4.],[5.,6.]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors are used in all kinds of operations (or \"Ops\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=[[1. 2.]\n",
      " [3. 4.]]\n",
      "tf.Tensor([4. 6.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "### Performing above method on specific axis\n",
    "print('a={}'.format(a))\n",
    "print(tf.reduce_sum(a,axis=0)) ## axis determine perform sum on which axis. axis =0 means perform sum along height or rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([1. 1.], shape=(2,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "### Converting to Tensor\n",
    "print(tf.convert_to_tensor([1,2,3]))\n",
    "print(tf.convert_to_tensor(np.ones(2))) ## as np.ones() is default np.float64 created tensor is also tf.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape:  (2, 2)\n"
     ]
    }
   ],
   "source": [
    "### Getting the shape of the Tensor\n",
    "print('a.shape: ',a.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "> What happens when we do mathematical operation with different shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:  tf.Tensor([[3. 3. 3.]], shape=(1, 3), dtype=float32)\n",
      "d:  tf.Tensor([5.], shape=(1,), dtype=float32)\n",
      "e:  tf.Tensor([1. 4. 5. 6. 8.], shape=(5,), dtype=float32)\n",
      "c*d: , tf.Tensor([[15. 15. 15.]], shape=(1, 3), dtype=float32)\n",
      "c*e :  tf.Tensor([ 5. 20. 25. 30. 40.], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c=tf.ones([1,3])*3\n",
    "d=tf.ones([1])*5\n",
    "e=tf.constant([1.,4.,5.,6.,8.])\n",
    "print('c: ',c)\n",
    "print('d: ',d)\n",
    "print('e: ',e)\n",
    "print('c*d: ,',tf.multiply(c,d))\n",
    "print('c*e : ',tf.multiply(d,e))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Reshaping\n",
    "print(tf.reshape(a,(-1,2))) ## Similar as np operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Tensor\n",
    ">Used in NLP tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'Hey' b'Hi' b'Namaste'], shape=(3,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "string_tensor=tf.constant(['Hey','Hi','Namaste'])\n",
    "print(string_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[b'Hey'],\n",
      " [b'Hi'],\n",
      " [b'Namaste']]>\n"
     ]
    }
   ],
   "source": [
    "## Splitting the string_tensor like sting dtype\n",
    "print(tf.strings.split(string_tensor,sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('vision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c93af7433719cf61beb232a937287b5f6ac44c5a03632b389ba7312dbdbeed85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
